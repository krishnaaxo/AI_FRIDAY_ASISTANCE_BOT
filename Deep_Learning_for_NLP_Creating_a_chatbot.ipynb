{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Deep Learning for NLP- Creating a chatbot.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnaaxo/AI_FRIDAY_ASSISTANCE_BOT/blob/main/Deep_Learning_for_NLP_Creating_a_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13KRdZUjEKnI"
      },
      "source": [
        "# Deep Learning for NLP - Creating a chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhBvR5vzEKnK"
      },
      "source": [
        "#Library Imports\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTt2mEhZEKnL"
      },
      "source": [
        "#retrieve training data\n",
        "with open('train_qa.txt', 'rb') as f:\n",
        "    train_data = pickle.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afb7ZSlKEKnL"
      },
      "source": [
        "#retrieve test data\n",
        "with open('test_qa.txt', 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hHSwW3JEKnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c42d53d-32e5-4d93-c292-67ea9aac16e6"
      },
      "source": [
        "#Number of training instances\n",
        "len(train_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Ys5PWJEKnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff97f187-b67c-4354-de1e-871dd121c83b"
      },
      "source": [
        "#Number of test instances\n",
        "len(test_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grgmVARoEKnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff7a2f6-e272-46a0-f60b-96e55ef6f03c"
      },
      "source": [
        "#Example of one of the instances\n",
        "train_data[10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Sandra',\n",
              "  'went',\n",
              "  'back',\n",
              "  'to',\n",
              "  'the',\n",
              "  'hallway',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'office',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
              " 'yes')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pYF1aFLEKnN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68b79249-a37b-4504-b564-59588085a3a8"
      },
      "source": [
        "' '.join(train_data[10][0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sandra went back to the hallway . Sandra moved to the office .'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQoQT4r6EKnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e8e6c16-eaab-43ff-8265-71b46d618658"
      },
      "source": [
        "' '.join(train_data[10][1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is Sandra in the office ?'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7mH1UKEKnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dc6e4d3-812f-444e-9b54-a46e1aa1b1ab"
      },
      "source": [
        "train_data[10][2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Lxm9ScEKnQ"
      },
      "source": [
        "#First we need to create a vocabulary with our data\n",
        "#For this we will use the training data only to - On the video it uses both\n",
        "#train and test \n",
        "#Might have to use training and test later, as the dataset has very\n",
        "#few words"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3dhfYNJEKnQ"
      },
      "source": [
        "#First we will build a set of all the words in the dataset:\n",
        "vocab = set()\n",
        "for story, question, answer in train_data:\n",
        "    vocab = vocab.union(set(story)) #Set returns unique words in the sentence\n",
        "                                    #Union returns the unique common elements from a two sets\n",
        "    vocab = vocab.union(set(question))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvoSE06OEKnR"
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5tpdNFMREKnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95161e3-9f63-4884-a8e4-62a016c202f0"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_AoDUuzEKnR"
      },
      "source": [
        "#Calculate len and add 1 for Keras placeholder - Placeholders are used to feed in the data to the network. \n",
        "#They need a data type, and have optional shape arguements.\n",
        "#They will be empty at first, and then the data will get fed into the placeholder\n",
        "vocab_len = len(vocab) + 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBJSkB8DEKnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6e99cc-aa04-4033-b1e4-c373c8f9d10f"
      },
      "source": [
        "vocab_len"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuLkWkcXEKnS"
      },
      "source": [
        "#Now we are going to calculate the longest story and the longest question\n",
        "#We need this for the Keras pad sequences. \n",
        "#Keras training layers expect all of the input to have the same length, so \n",
        "#we need to pad \n",
        "all_data = test_data + train_data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_7rq1GwEKnS"
      },
      "source": [
        "all_story_lens = [len(data[0]) for data in all_data]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgYQJmHjEKnS"
      },
      "source": [
        "max_story_len = (max(all_story_lens))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlxUsrq3EKnS"
      },
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWI5naaXEKnT"
      },
      "source": [
        "## Vectorizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p56KxkDEKnT"
      },
      "source": [
        "First, we will go through a manual process of how to vectorize the data, and then we will create a function that does this automatically for us. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG8kKGNDEKnT"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J28MwA9pEKnT"
      },
      "source": [
        "#Create an instance of the tokenizer object:\n",
        "tokenizer = Tokenizer(filters = [])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4e6pjLuEKnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b5e8a4-fb1a-4a29-a6f6-dc08567e569e"
      },
      "source": [
        "#Dictionary that maps every word in our vocab to an index\n",
        "# It has been automatically lowercased\n",
        "#This tokenizer can give different indexes for different words depending on when we run it\n",
        "tokenizer.word_index"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 18,\n",
              " '?': 32,\n",
              " 'apple': 27,\n",
              " 'back': 15,\n",
              " 'bathroom': 25,\n",
              " 'bedroom': 26,\n",
              " 'daniel': 35,\n",
              " 'discarded': 2,\n",
              " 'down': 11,\n",
              " 'dropped': 16,\n",
              " 'football': 6,\n",
              " 'garden': 17,\n",
              " 'got': 28,\n",
              " 'grabbed': 22,\n",
              " 'hallway': 8,\n",
              " 'in': 34,\n",
              " 'is': 37,\n",
              " 'john': 3,\n",
              " 'journeyed': 24,\n",
              " 'kitchen': 21,\n",
              " 'left': 13,\n",
              " 'mary': 36,\n",
              " 'milk': 20,\n",
              " 'moved': 4,\n",
              " 'no': 30,\n",
              " 'office': 31,\n",
              " 'picked': 5,\n",
              " 'put': 29,\n",
              " 'sandra': 1,\n",
              " 'the': 9,\n",
              " 'there': 14,\n",
              " 'to': 10,\n",
              " 'took': 33,\n",
              " 'travelled': 23,\n",
              " 'up': 12,\n",
              " 'went': 7,\n",
              " 'yes': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JdBslgtEKnU"
      },
      "source": [
        "#Tokenize the stories, questions and answers:\n",
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wIW8yOtEKnU"
      },
      "source": [
        "#Separating each of the elements\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question) \n",
        "    train_answers.append(answer)\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUko8nXREKnU"
      },
      "source": [
        "#Coverting the text into the indexes \n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAZjtw0BEKnV"
      },
      "source": [
        "#Create a function for vectorizing the stories, questions and answers:\n",
        "def vectorize_stories(data,word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
        "    #vectorized stories:\n",
        "    X = []\n",
        "    #vectorized questions:\n",
        "    Xq = []\n",
        "    #vectorized answers:\n",
        "    Y = []\n",
        "    \n",
        "    for story, question, answer in data:\n",
        "        #Getting indexes for each word in the story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        #Getting indexes for each word in the story\n",
        "        xq = [word_index[word.lower()] for word in question]\n",
        "        #For the answers\n",
        "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    #Now we have to pad these sequences:\n",
        "    return(pad_sequences(X,maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq5F2qH3EKnV"
      },
      "source": [
        "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud66sz9uEKnV"
      },
      "source": [
        "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74fbusCzEKnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da798100-7dfa-434d-a142-1c71d6f0dc01"
      },
      "source": [
        "inputs_train[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0, 36,  4, 10,  9, 25, 18,  1, 24, 10,\n",
              "        9, 26, 18], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqiEg_1QEKnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc740905-d780-4152-9d69-8b3a82035782"
      },
      "source": [
        "train_story_text[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bathroom',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'journeyed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIfVn8_EKnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e6575f-c39f-462d-b277-cccb26497514"
      },
      "source": [
        "train_story_seq[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36, 4, 10, 9, 25, 18, 1, 24, 10, 9, 26, 18]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPV9v8agEKnY"
      },
      "source": [
        "## Building the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzmY70fEKnY"
      },
      "source": [
        "#Imports\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDHaBxyJEKnY"
      },
      "source": [
        "# We need to create the placeholders \n",
        "#The Input function is used to create a keras tensor\n",
        "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
        "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
        "input_sequence = Input((max_story_len,)) #As we dont know batch size yet\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvvN0ncmEKnZ"
      },
      "source": [
        "#Create input encoder M:\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
        "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJVJQ8l_EKna"
      },
      "source": [
        "#Create input encoder C:\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "\n",
        "#Outputs: (samples, story_maxlen, max_question_len)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKG4_8M2EKna"
      },
      "source": [
        "#Create question encoder:\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
        "question_encoder.add(Dropout(0.3))\n",
        "\n",
        "#Outputs: (samples, question_maxlen, embedding_dim)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnnWWDa_EKna"
      },
      "source": [
        "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNPo4BQxEKna"
      },
      "source": [
        "#Use dot product to compute similarity between input encoded m and question \n",
        "#Like in the paper:\n",
        "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNAxxj6JEKnb"
      },
      "source": [
        "#For the response we want to add this match with the ouput of input_encoded_c\n",
        "response = add([match,input_encoded_c])\n",
        "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phvhMw6UEKnb"
      },
      "source": [
        "#Once we have the response we can concatenate it with the question encoded:\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naNI8wFAEKnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b62d23-0cd6-4b70-ba9c-42ec2b50d5c0"
      },
      "source": [
        "answer"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPkhYar5EKnb"
      },
      "source": [
        "# Reduce the answer tensor with a RNN (LSTM)\n",
        "answer = LSTM(32)(answer)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj2igQxhEKnc"
      },
      "source": [
        "#Regularization with dropout:\n",
        "answer = Dropout(0.5)(answer)\n",
        "#Output layer:\n",
        "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLJv4tfiEKnc"
      },
      "source": [
        "#Now we need to output a probability distribution for the vocab, using softmax:\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyOFBFLpEKnc"
      },
      "source": [
        "#Now we build the final model:\n",
        "model = Model([input_sequence,question], answer)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBVqafP-EKnc"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#Categorical instead of binary cross entropy as because of the way we are training\n",
        "#we could actually see any of the words from the vocab as output\n",
        "#however, we should only see yes or no"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWB_4h_0EKnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cbcae1-07e8-40d5-ed75-c85fe3d8c114"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxc9fotwEKnc"
      },
      "source": [
        "## Training and testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLBbRfvsEKnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a74850f-a93e-4bd9-877d-32f4069695c8"
      },
      "source": [
        "history = model.fit([inputs_train,questions_train],answers_train, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "313/313 [==============================] - 11s 11ms/step - loss: 0.9581 - accuracy: 0.4997 - val_loss: 0.6978 - val_accuracy: 0.4970\n",
            "Epoch 2/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7106 - accuracy: 0.5011 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
            "Epoch 3/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6969 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 4/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6961 - accuracy: 0.5008 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 5/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6943 - accuracy: 0.4971 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 6/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6953 - accuracy: 0.4949 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
            "Epoch 7/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6944 - accuracy: 0.5012 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 8/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6947 - accuracy: 0.5007 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
            "Epoch 9/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6936 - val_accuracy: 0.5200\n",
            "Epoch 10/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6882 - accuracy: 0.5319 - val_loss: 0.6833 - val_accuracy: 0.5730\n",
            "Epoch 11/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6644 - accuracy: 0.5808 - val_loss: 0.6436 - val_accuracy: 0.6640\n",
            "Epoch 12/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6335 - accuracy: 0.6427 - val_loss: 0.6218 - val_accuracy: 0.6740\n",
            "Epoch 13/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6275 - accuracy: 0.6481 - val_loss: 0.6163 - val_accuracy: 0.6640\n",
            "Epoch 14/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6187 - accuracy: 0.6638 - val_loss: 0.6229 - val_accuracy: 0.6590\n",
            "Epoch 15/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6053 - accuracy: 0.6734 - val_loss: 0.6109 - val_accuracy: 0.6570\n",
            "Epoch 16/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5922 - accuracy: 0.6875 - val_loss: 0.5817 - val_accuracy: 0.6800\n",
            "Epoch 17/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5781 - accuracy: 0.6965 - val_loss: 0.5543 - val_accuracy: 0.7210\n",
            "Epoch 18/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.5558 - accuracy: 0.7186 - val_loss: 0.5215 - val_accuracy: 0.7480\n",
            "Epoch 19/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5299 - accuracy: 0.7408 - val_loss: 0.4941 - val_accuracy: 0.7670\n",
            "Epoch 20/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5176 - accuracy: 0.7488 - val_loss: 0.4755 - val_accuracy: 0.7730\n",
            "Epoch 21/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4974 - accuracy: 0.7633 - val_loss: 0.4775 - val_accuracy: 0.7830\n",
            "Epoch 22/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4951 - accuracy: 0.7647 - val_loss: 0.4672 - val_accuracy: 0.7780\n",
            "Epoch 23/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4757 - accuracy: 0.7769 - val_loss: 0.4592 - val_accuracy: 0.7940\n",
            "Epoch 24/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4670 - accuracy: 0.7833 - val_loss: 0.4397 - val_accuracy: 0.7970\n",
            "Epoch 25/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4569 - accuracy: 0.7832 - val_loss: 0.4393 - val_accuracy: 0.7940\n",
            "Epoch 26/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4512 - accuracy: 0.7870 - val_loss: 0.4582 - val_accuracy: 0.7930\n",
            "Epoch 27/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4427 - accuracy: 0.7911 - val_loss: 0.4331 - val_accuracy: 0.7910\n",
            "Epoch 28/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4447 - accuracy: 0.7967 - val_loss: 0.4443 - val_accuracy: 0.7870\n",
            "Epoch 29/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4336 - accuracy: 0.8027 - val_loss: 0.4243 - val_accuracy: 0.8020\n",
            "Epoch 30/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4228 - accuracy: 0.8037 - val_loss: 0.4171 - val_accuracy: 0.8030\n",
            "Epoch 31/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4208 - accuracy: 0.8006 - val_loss: 0.4213 - val_accuracy: 0.8020\n",
            "Epoch 32/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4239 - accuracy: 0.8027 - val_loss: 0.4136 - val_accuracy: 0.7930\n",
            "Epoch 33/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4133 - accuracy: 0.8061 - val_loss: 0.4151 - val_accuracy: 0.7970\n",
            "Epoch 34/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4080 - accuracy: 0.8126 - val_loss: 0.4065 - val_accuracy: 0.8050\n",
            "Epoch 35/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4079 - accuracy: 0.8130 - val_loss: 0.4104 - val_accuracy: 0.7960\n",
            "Epoch 36/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3998 - accuracy: 0.8147 - val_loss: 0.4063 - val_accuracy: 0.7940\n",
            "Epoch 37/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3964 - accuracy: 0.8184 - val_loss: 0.4302 - val_accuracy: 0.7980\n",
            "Epoch 38/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3918 - accuracy: 0.8159 - val_loss: 0.4228 - val_accuracy: 0.7970\n",
            "Epoch 39/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3925 - accuracy: 0.8141 - val_loss: 0.4131 - val_accuracy: 0.8030\n",
            "Epoch 40/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3880 - accuracy: 0.8177 - val_loss: 0.4169 - val_accuracy: 0.8090\n",
            "Epoch 41/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3903 - accuracy: 0.8193 - val_loss: 0.4267 - val_accuracy: 0.8010\n",
            "Epoch 42/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3825 - accuracy: 0.8217 - val_loss: 0.4164 - val_accuracy: 0.7960\n",
            "Epoch 43/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3856 - accuracy: 0.8207 - val_loss: 0.4217 - val_accuracy: 0.8030\n",
            "Epoch 44/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3764 - accuracy: 0.8220 - val_loss: 0.4149 - val_accuracy: 0.8070\n",
            "Epoch 45/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3781 - accuracy: 0.8206 - val_loss: 0.4115 - val_accuracy: 0.8000\n",
            "Epoch 46/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3762 - accuracy: 0.8243 - val_loss: 0.4095 - val_accuracy: 0.8040\n",
            "Epoch 47/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3724 - accuracy: 0.8270 - val_loss: 0.4276 - val_accuracy: 0.8050\n",
            "Epoch 48/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3706 - accuracy: 0.8308 - val_loss: 0.4220 - val_accuracy: 0.8040\n",
            "Epoch 49/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3695 - accuracy: 0.8292 - val_loss: 0.4286 - val_accuracy: 0.8000\n",
            "Epoch 50/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3690 - accuracy: 0.8293 - val_loss: 0.4118 - val_accuracy: 0.8030\n",
            "Epoch 51/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3655 - accuracy: 0.8300 - val_loss: 0.4171 - val_accuracy: 0.8000\n",
            "Epoch 52/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3640 - accuracy: 0.8324 - val_loss: 0.4202 - val_accuracy: 0.8060\n",
            "Epoch 53/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3669 - accuracy: 0.8293 - val_loss: 0.4378 - val_accuracy: 0.7900\n",
            "Epoch 54/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3631 - accuracy: 0.8300 - val_loss: 0.4389 - val_accuracy: 0.7960\n",
            "Epoch 55/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3583 - accuracy: 0.8306 - val_loss: 0.4378 - val_accuracy: 0.7920\n",
            "Epoch 56/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3584 - accuracy: 0.8326 - val_loss: 0.4245 - val_accuracy: 0.7910\n",
            "Epoch 57/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3590 - accuracy: 0.8360 - val_loss: 0.4237 - val_accuracy: 0.7920\n",
            "Epoch 58/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3528 - accuracy: 0.8360 - val_loss: 0.4427 - val_accuracy: 0.7980\n",
            "Epoch 59/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3499 - accuracy: 0.8382 - val_loss: 0.4571 - val_accuracy: 0.7920\n",
            "Epoch 60/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3511 - accuracy: 0.8374 - val_loss: 0.4598 - val_accuracy: 0.7930\n",
            "Epoch 61/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3502 - accuracy: 0.8382 - val_loss: 0.4457 - val_accuracy: 0.8070\n",
            "Epoch 62/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3481 - accuracy: 0.8407 - val_loss: 0.4379 - val_accuracy: 0.7910\n",
            "Epoch 63/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3442 - accuracy: 0.8437 - val_loss: 0.4518 - val_accuracy: 0.7960\n",
            "Epoch 64/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3415 - accuracy: 0.8427 - val_loss: 0.4290 - val_accuracy: 0.8000\n",
            "Epoch 65/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3439 - accuracy: 0.8417 - val_loss: 0.4441 - val_accuracy: 0.7910\n",
            "Epoch 66/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3407 - accuracy: 0.8448 - val_loss: 0.4604 - val_accuracy: 0.7980\n",
            "Epoch 67/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3313 - accuracy: 0.8456 - val_loss: 0.4638 - val_accuracy: 0.7910\n",
            "Epoch 68/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3319 - accuracy: 0.8445 - val_loss: 0.4498 - val_accuracy: 0.7910\n",
            "Epoch 69/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3324 - accuracy: 0.8507 - val_loss: 0.4916 - val_accuracy: 0.7910\n",
            "Epoch 70/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3273 - accuracy: 0.8506 - val_loss: 0.4598 - val_accuracy: 0.7970\n",
            "Epoch 71/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3307 - accuracy: 0.8486 - val_loss: 0.4601 - val_accuracy: 0.7890\n",
            "Epoch 72/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3331 - accuracy: 0.8485 - val_loss: 0.4738 - val_accuracy: 0.7870\n",
            "Epoch 73/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3223 - accuracy: 0.8538 - val_loss: 0.4706 - val_accuracy: 0.7850\n",
            "Epoch 74/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3228 - accuracy: 0.8539 - val_loss: 0.4678 - val_accuracy: 0.7890\n",
            "Epoch 75/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3221 - accuracy: 0.8482 - val_loss: 0.5097 - val_accuracy: 0.7900\n",
            "Epoch 76/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3211 - accuracy: 0.8524 - val_loss: 0.4784 - val_accuracy: 0.7810\n",
            "Epoch 77/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3166 - accuracy: 0.8589 - val_loss: 0.4925 - val_accuracy: 0.7820\n",
            "Epoch 78/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3181 - accuracy: 0.8545 - val_loss: 0.4731 - val_accuracy: 0.7880\n",
            "Epoch 79/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3156 - accuracy: 0.8603 - val_loss: 0.5048 - val_accuracy: 0.7930\n",
            "Epoch 80/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3173 - accuracy: 0.8584 - val_loss: 0.4963 - val_accuracy: 0.7900\n",
            "Epoch 81/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3211 - accuracy: 0.8534 - val_loss: 0.4877 - val_accuracy: 0.7850\n",
            "Epoch 82/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3108 - accuracy: 0.8576 - val_loss: 0.4930 - val_accuracy: 0.7850\n",
            "Epoch 83/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3101 - accuracy: 0.8604 - val_loss: 0.5039 - val_accuracy: 0.7880\n",
            "Epoch 84/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3080 - accuracy: 0.8640 - val_loss: 0.5068 - val_accuracy: 0.7820\n",
            "Epoch 85/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3043 - accuracy: 0.8627 - val_loss: 0.5019 - val_accuracy: 0.7780\n",
            "Epoch 86/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3041 - accuracy: 0.8613 - val_loss: 0.5095 - val_accuracy: 0.7850\n",
            "Epoch 87/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2975 - accuracy: 0.8649 - val_loss: 0.5180 - val_accuracy: 0.7940\n",
            "Epoch 88/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3054 - accuracy: 0.8636 - val_loss: 0.5081 - val_accuracy: 0.7800\n",
            "Epoch 89/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2970 - accuracy: 0.8672 - val_loss: 0.5274 - val_accuracy: 0.7880\n",
            "Epoch 90/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3013 - accuracy: 0.8672 - val_loss: 0.5317 - val_accuracy: 0.7830\n",
            "Epoch 91/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2929 - accuracy: 0.8687 - val_loss: 0.5679 - val_accuracy: 0.7740\n",
            "Epoch 92/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2924 - accuracy: 0.8691 - val_loss: 0.5404 - val_accuracy: 0.7890\n",
            "Epoch 93/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2928 - accuracy: 0.8673 - val_loss: 0.5321 - val_accuracy: 0.7740\n",
            "Epoch 94/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2961 - accuracy: 0.8669 - val_loss: 0.5538 - val_accuracy: 0.7800\n",
            "Epoch 95/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2923 - accuracy: 0.8678 - val_loss: 0.5227 - val_accuracy: 0.7810\n",
            "Epoch 96/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2881 - accuracy: 0.8683 - val_loss: 0.5464 - val_accuracy: 0.7760\n",
            "Epoch 97/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2913 - accuracy: 0.8732 - val_loss: 0.5605 - val_accuracy: 0.7790\n",
            "Epoch 98/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2854 - accuracy: 0.8729 - val_loss: 0.5488 - val_accuracy: 0.7740\n",
            "Epoch 99/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2872 - accuracy: 0.8713 - val_loss: 0.5676 - val_accuracy: 0.7910\n",
            "Epoch 100/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2821 - accuracy: 0.8741 - val_loss: 0.5459 - val_accuracy: 0.7840\n",
            "Epoch 101/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2869 - accuracy: 0.8712 - val_loss: 0.5604 - val_accuracy: 0.7840\n",
            "Epoch 102/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2864 - accuracy: 0.8726 - val_loss: 0.5606 - val_accuracy: 0.7940\n",
            "Epoch 103/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2792 - accuracy: 0.8751 - val_loss: 0.5731 - val_accuracy: 0.7890\n",
            "Epoch 104/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2770 - accuracy: 0.8800 - val_loss: 0.5407 - val_accuracy: 0.7750\n",
            "Epoch 105/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2796 - accuracy: 0.8741 - val_loss: 0.5607 - val_accuracy: 0.7870\n",
            "Epoch 106/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2791 - accuracy: 0.8760 - val_loss: 0.5843 - val_accuracy: 0.7830\n",
            "Epoch 107/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2761 - accuracy: 0.8781 - val_loss: 0.5670 - val_accuracy: 0.7830\n",
            "Epoch 108/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2719 - accuracy: 0.8828 - val_loss: 0.5757 - val_accuracy: 0.7770\n",
            "Epoch 109/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2749 - accuracy: 0.8777 - val_loss: 0.5729 - val_accuracy: 0.7730\n",
            "Epoch 110/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2721 - accuracy: 0.8804 - val_loss: 0.6071 - val_accuracy: 0.7840\n",
            "Epoch 111/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2712 - accuracy: 0.8782 - val_loss: 0.6090 - val_accuracy: 0.7780\n",
            "Epoch 112/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2749 - accuracy: 0.8800 - val_loss: 0.5797 - val_accuracy: 0.7810\n",
            "Epoch 113/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2648 - accuracy: 0.8798 - val_loss: 0.5957 - val_accuracy: 0.7730\n",
            "Epoch 114/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2734 - accuracy: 0.8765 - val_loss: 0.5869 - val_accuracy: 0.7780\n",
            "Epoch 115/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2650 - accuracy: 0.8805 - val_loss: 0.5662 - val_accuracy: 0.7760\n",
            "Epoch 116/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2672 - accuracy: 0.8876 - val_loss: 0.5881 - val_accuracy: 0.7690\n",
            "Epoch 117/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2596 - accuracy: 0.8868 - val_loss: 0.5746 - val_accuracy: 0.7760\n",
            "Epoch 118/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2625 - accuracy: 0.8852 - val_loss: 0.5983 - val_accuracy: 0.7800\n",
            "Epoch 119/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2626 - accuracy: 0.8844 - val_loss: 0.5727 - val_accuracy: 0.7810\n",
            "Epoch 120/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2654 - accuracy: 0.8843 - val_loss: 0.6130 - val_accuracy: 0.7760\n",
            "Epoch 121/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2555 - accuracy: 0.8873 - val_loss: 0.5613 - val_accuracy: 0.7650\n",
            "Epoch 122/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2592 - accuracy: 0.8872 - val_loss: 0.5993 - val_accuracy: 0.7750\n",
            "Epoch 123/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2545 - accuracy: 0.8852 - val_loss: 0.6182 - val_accuracy: 0.7760\n",
            "Epoch 124/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2583 - accuracy: 0.8856 - val_loss: 0.6180 - val_accuracy: 0.7760\n",
            "Epoch 125/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2597 - accuracy: 0.8865 - val_loss: 0.5767 - val_accuracy: 0.7710\n",
            "Epoch 126/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2568 - accuracy: 0.8894 - val_loss: 0.6005 - val_accuracy: 0.7780\n",
            "Epoch 127/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2588 - accuracy: 0.8845 - val_loss: 0.6661 - val_accuracy: 0.7780\n",
            "Epoch 128/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2539 - accuracy: 0.8896 - val_loss: 0.6498 - val_accuracy: 0.7760\n",
            "Epoch 129/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2539 - accuracy: 0.8901 - val_loss: 0.6351 - val_accuracy: 0.7700\n",
            "Epoch 130/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2479 - accuracy: 0.8888 - val_loss: 0.6159 - val_accuracy: 0.7550\n",
            "Epoch 131/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2554 - accuracy: 0.8867 - val_loss: 0.6779 - val_accuracy: 0.7550\n",
            "Epoch 132/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2479 - accuracy: 0.8907 - val_loss: 0.6590 - val_accuracy: 0.7680\n",
            "Epoch 133/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2489 - accuracy: 0.8934 - val_loss: 0.6599 - val_accuracy: 0.7780\n",
            "Epoch 134/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2427 - accuracy: 0.8925 - val_loss: 0.6850 - val_accuracy: 0.7770\n",
            "Epoch 135/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2501 - accuracy: 0.8931 - val_loss: 0.6652 - val_accuracy: 0.7610\n",
            "Epoch 136/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2441 - accuracy: 0.8918 - val_loss: 0.6721 - val_accuracy: 0.7680\n",
            "Epoch 137/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2480 - accuracy: 0.8897 - val_loss: 0.6636 - val_accuracy: 0.7800\n",
            "Epoch 138/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2362 - accuracy: 0.8946 - val_loss: 0.6666 - val_accuracy: 0.7680\n",
            "Epoch 139/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2365 - accuracy: 0.8954 - val_loss: 0.7127 - val_accuracy: 0.7700\n",
            "Epoch 140/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2405 - accuracy: 0.8944 - val_loss: 0.6748 - val_accuracy: 0.7750\n",
            "Epoch 141/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2395 - accuracy: 0.8965 - val_loss: 0.6834 - val_accuracy: 0.7740\n",
            "Epoch 142/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.2432 - accuracy: 0.8919 - val_loss: 0.6689 - val_accuracy: 0.7730\n",
            "Epoch 143/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2342 - accuracy: 0.8997 - val_loss: 0.7037 - val_accuracy: 0.7620\n",
            "Epoch 144/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2378 - accuracy: 0.8955 - val_loss: 0.6683 - val_accuracy: 0.7740\n",
            "Epoch 145/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2347 - accuracy: 0.9001 - val_loss: 0.7288 - val_accuracy: 0.7690\n",
            "Epoch 146/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2406 - accuracy: 0.8989 - val_loss: 0.7009 - val_accuracy: 0.7750\n",
            "Epoch 147/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2332 - accuracy: 0.8990 - val_loss: 0.7175 - val_accuracy: 0.7800\n",
            "Epoch 148/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2334 - accuracy: 0.9002 - val_loss: 0.7034 - val_accuracy: 0.7660\n",
            "Epoch 149/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2342 - accuracy: 0.8990 - val_loss: 0.7219 - val_accuracy: 0.7790\n",
            "Epoch 150/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2383 - accuracy: 0.8959 - val_loss: 0.7177 - val_accuracy: 0.7750\n",
            "Epoch 151/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2376 - accuracy: 0.8973 - val_loss: 0.7281 - val_accuracy: 0.7800\n",
            "Epoch 152/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2305 - accuracy: 0.9006 - val_loss: 0.6821 - val_accuracy: 0.7760\n",
            "Epoch 153/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2339 - accuracy: 0.8988 - val_loss: 0.6937 - val_accuracy: 0.7780\n",
            "Epoch 154/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2312 - accuracy: 0.9008 - val_loss: 0.7211 - val_accuracy: 0.7740\n",
            "Epoch 155/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2254 - accuracy: 0.9009 - val_loss: 0.6998 - val_accuracy: 0.7750\n",
            "Epoch 156/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2268 - accuracy: 0.9040 - val_loss: 0.7321 - val_accuracy: 0.7770\n",
            "Epoch 157/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2246 - accuracy: 0.9054 - val_loss: 0.7182 - val_accuracy: 0.7770\n",
            "Epoch 158/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2286 - accuracy: 0.9056 - val_loss: 0.7352 - val_accuracy: 0.7790\n",
            "Epoch 159/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2247 - accuracy: 0.9043 - val_loss: 0.7073 - val_accuracy: 0.7630\n",
            "Epoch 160/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.7048 - val_accuracy: 0.7770\n",
            "Epoch 161/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2298 - accuracy: 0.9026 - val_loss: 0.6922 - val_accuracy: 0.7770\n",
            "Epoch 162/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2280 - accuracy: 0.9009 - val_loss: 0.7046 - val_accuracy: 0.7760\n",
            "Epoch 163/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2237 - accuracy: 0.9052 - val_loss: 0.7120 - val_accuracy: 0.7620\n",
            "Epoch 164/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2224 - accuracy: 0.9036 - val_loss: 0.6837 - val_accuracy: 0.7720\n",
            "Epoch 165/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2221 - accuracy: 0.9038 - val_loss: 0.7387 - val_accuracy: 0.7750\n",
            "Epoch 166/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2141 - accuracy: 0.9069 - val_loss: 0.7090 - val_accuracy: 0.7690\n",
            "Epoch 167/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2172 - accuracy: 0.9070 - val_loss: 0.7632 - val_accuracy: 0.7750\n",
            "Epoch 168/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2197 - accuracy: 0.9080 - val_loss: 0.7291 - val_accuracy: 0.7820\n",
            "Epoch 169/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2179 - accuracy: 0.9108 - val_loss: 0.7466 - val_accuracy: 0.7790\n",
            "Epoch 170/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2225 - accuracy: 0.9068 - val_loss: 0.7219 - val_accuracy: 0.7790\n",
            "Epoch 171/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2144 - accuracy: 0.9093 - val_loss: 0.6942 - val_accuracy: 0.7870\n",
            "Epoch 172/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2127 - accuracy: 0.9128 - val_loss: 0.7386 - val_accuracy: 0.7860\n",
            "Epoch 173/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2086 - accuracy: 0.9123 - val_loss: 0.7013 - val_accuracy: 0.7820\n",
            "Epoch 174/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2094 - accuracy: 0.9103 - val_loss: 0.7550 - val_accuracy: 0.7820\n",
            "Epoch 175/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2042 - accuracy: 0.9124 - val_loss: 0.7125 - val_accuracy: 0.7900\n",
            "Epoch 176/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2062 - accuracy: 0.9130 - val_loss: 0.7323 - val_accuracy: 0.7900\n",
            "Epoch 177/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2081 - accuracy: 0.9119 - val_loss: 0.7150 - val_accuracy: 0.7900\n",
            "Epoch 178/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1983 - accuracy: 0.9193 - val_loss: 0.7440 - val_accuracy: 0.7880\n",
            "Epoch 179/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2053 - accuracy: 0.9141 - val_loss: 0.7555 - val_accuracy: 0.7850\n",
            "Epoch 180/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2069 - accuracy: 0.9122 - val_loss: 0.7269 - val_accuracy: 0.7910\n",
            "Epoch 181/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1996 - accuracy: 0.9196 - val_loss: 0.7660 - val_accuracy: 0.7800\n",
            "Epoch 182/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2031 - accuracy: 0.9158 - val_loss: 0.7889 - val_accuracy: 0.7870\n",
            "Epoch 183/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2038 - accuracy: 0.9118 - val_loss: 0.7521 - val_accuracy: 0.7860\n",
            "Epoch 184/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2050 - accuracy: 0.9156 - val_loss: 0.7575 - val_accuracy: 0.7810\n",
            "Epoch 185/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1985 - accuracy: 0.9172 - val_loss: 0.7409 - val_accuracy: 0.7860\n",
            "Epoch 186/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1997 - accuracy: 0.9164 - val_loss: 0.7239 - val_accuracy: 0.7870\n",
            "Epoch 187/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1990 - accuracy: 0.9164 - val_loss: 0.7244 - val_accuracy: 0.7920\n",
            "Epoch 188/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1957 - accuracy: 0.9184 - val_loss: 0.7168 - val_accuracy: 0.7960\n",
            "Epoch 189/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2010 - accuracy: 0.9169 - val_loss: 0.7305 - val_accuracy: 0.7810\n",
            "Epoch 190/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1936 - accuracy: 0.9192 - val_loss: 0.6897 - val_accuracy: 0.7870\n",
            "Epoch 191/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1891 - accuracy: 0.9252 - val_loss: 0.7609 - val_accuracy: 0.7840\n",
            "Epoch 192/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1950 - accuracy: 0.9217 - val_loss: 0.7727 - val_accuracy: 0.7880\n",
            "Epoch 193/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1986 - accuracy: 0.9181 - val_loss: 0.7404 - val_accuracy: 0.7840\n",
            "Epoch 194/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1954 - accuracy: 0.9224 - val_loss: 0.7515 - val_accuracy: 0.7770\n",
            "Epoch 195/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1952 - accuracy: 0.9199 - val_loss: 0.7269 - val_accuracy: 0.7860\n",
            "Epoch 196/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1911 - accuracy: 0.9213 - val_loss: 0.7450 - val_accuracy: 0.7880\n",
            "Epoch 197/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1890 - accuracy: 0.9234 - val_loss: 0.7334 - val_accuracy: 0.7820\n",
            "Epoch 198/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1878 - accuracy: 0.9231 - val_loss: 0.7434 - val_accuracy: 0.7870\n",
            "Epoch 199/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1948 - accuracy: 0.9218 - val_loss: 0.7948 - val_accuracy: 0.7930\n",
            "Epoch 200/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1908 - accuracy: 0.9222 - val_loss: 0.7570 - val_accuracy: 0.7980\n",
            "Epoch 201/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1892 - accuracy: 0.9225 - val_loss: 0.7401 - val_accuracy: 0.7870\n",
            "Epoch 202/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1767 - accuracy: 0.9261 - val_loss: 0.8006 - val_accuracy: 0.7780\n",
            "Epoch 203/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1890 - accuracy: 0.9224 - val_loss: 0.7789 - val_accuracy: 0.7870\n",
            "Epoch 204/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1861 - accuracy: 0.9237 - val_loss: 0.7359 - val_accuracy: 0.7900\n",
            "Epoch 205/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1817 - accuracy: 0.9228 - val_loss: 0.7849 - val_accuracy: 0.7790\n",
            "Epoch 206/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1786 - accuracy: 0.9278 - val_loss: 0.7652 - val_accuracy: 0.7860\n",
            "Epoch 207/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1877 - accuracy: 0.9228 - val_loss: 0.7506 - val_accuracy: 0.7810\n",
            "Epoch 208/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1815 - accuracy: 0.9272 - val_loss: 0.7933 - val_accuracy: 0.7740\n",
            "Epoch 209/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1771 - accuracy: 0.9294 - val_loss: 0.7672 - val_accuracy: 0.7900\n",
            "Epoch 210/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1840 - accuracy: 0.9257 - val_loss: 0.7572 - val_accuracy: 0.7960\n",
            "Epoch 211/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1829 - accuracy: 0.9294 - val_loss: 0.7650 - val_accuracy: 0.7810\n",
            "Epoch 212/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1850 - accuracy: 0.9240 - val_loss: 0.7731 - val_accuracy: 0.7830\n",
            "Epoch 213/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1738 - accuracy: 0.9321 - val_loss: 0.8072 - val_accuracy: 0.7770\n",
            "Epoch 214/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1756 - accuracy: 0.9286 - val_loss: 0.8265 - val_accuracy: 0.7810\n",
            "Epoch 215/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1802 - accuracy: 0.9266 - val_loss: 0.8118 - val_accuracy: 0.7810\n",
            "Epoch 216/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1817 - accuracy: 0.9263 - val_loss: 0.7939 - val_accuracy: 0.7910\n",
            "Epoch 217/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1810 - accuracy: 0.9283 - val_loss: 0.7883 - val_accuracy: 0.7950\n",
            "Epoch 218/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1828 - accuracy: 0.9258 - val_loss: 0.7800 - val_accuracy: 0.7830\n",
            "Epoch 219/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1722 - accuracy: 0.9322 - val_loss: 0.7834 - val_accuracy: 0.7810\n",
            "Epoch 220/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1781 - accuracy: 0.9277 - val_loss: 0.7908 - val_accuracy: 0.7730\n",
            "Epoch 221/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1687 - accuracy: 0.9335 - val_loss: 0.8172 - val_accuracy: 0.7860\n",
            "Epoch 222/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1700 - accuracy: 0.9317 - val_loss: 0.7968 - val_accuracy: 0.7940\n",
            "Epoch 223/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1736 - accuracy: 0.9320 - val_loss: 0.7645 - val_accuracy: 0.7800\n",
            "Epoch 224/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1710 - accuracy: 0.9319 - val_loss: 0.8228 - val_accuracy: 0.7900\n",
            "Epoch 225/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1651 - accuracy: 0.9352 - val_loss: 0.8622 - val_accuracy: 0.7760\n",
            "Epoch 226/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1743 - accuracy: 0.9313 - val_loss: 0.8145 - val_accuracy: 0.7880\n",
            "Epoch 227/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1726 - accuracy: 0.9299 - val_loss: 0.8229 - val_accuracy: 0.7770\n",
            "Epoch 228/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1738 - accuracy: 0.9292 - val_loss: 0.8420 - val_accuracy: 0.7740\n",
            "Epoch 229/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1713 - accuracy: 0.9324 - val_loss: 0.8278 - val_accuracy: 0.7820\n",
            "Epoch 230/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1708 - accuracy: 0.9301 - val_loss: 0.8039 - val_accuracy: 0.7840\n",
            "Epoch 231/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1683 - accuracy: 0.9317 - val_loss: 0.8254 - val_accuracy: 0.7820\n",
            "Epoch 232/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1719 - accuracy: 0.9308 - val_loss: 0.8625 - val_accuracy: 0.7800\n",
            "Epoch 233/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.7973 - val_accuracy: 0.7790\n",
            "Epoch 234/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1731 - accuracy: 0.9302 - val_loss: 0.8283 - val_accuracy: 0.7830\n",
            "Epoch 235/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1714 - accuracy: 0.9331 - val_loss: 0.8576 - val_accuracy: 0.7830\n",
            "Epoch 236/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1649 - accuracy: 0.9347 - val_loss: 0.8303 - val_accuracy: 0.7850\n",
            "Epoch 237/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1640 - accuracy: 0.9336 - val_loss: 0.8531 - val_accuracy: 0.7820\n",
            "Epoch 238/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1644 - accuracy: 0.9361 - val_loss: 0.8722 - val_accuracy: 0.7750\n",
            "Epoch 239/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1756 - accuracy: 0.9319 - val_loss: 0.8349 - val_accuracy: 0.7820\n",
            "Epoch 240/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1590 - accuracy: 0.9371 - val_loss: 0.8470 - val_accuracy: 0.7830\n",
            "Epoch 241/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1631 - accuracy: 0.9333 - val_loss: 0.8459 - val_accuracy: 0.7810\n",
            "Epoch 242/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1603 - accuracy: 0.9346 - val_loss: 0.8438 - val_accuracy: 0.7860\n",
            "Epoch 243/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1616 - accuracy: 0.9353 - val_loss: 0.7963 - val_accuracy: 0.7860\n",
            "Epoch 244/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1648 - accuracy: 0.9355 - val_loss: 0.8589 - val_accuracy: 0.7730\n",
            "Epoch 245/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1592 - accuracy: 0.9348 - val_loss: 0.8106 - val_accuracy: 0.7810\n",
            "Epoch 246/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1649 - accuracy: 0.9342 - val_loss: 0.8478 - val_accuracy: 0.7820\n",
            "Epoch 247/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1653 - accuracy: 0.9341 - val_loss: 0.8518 - val_accuracy: 0.7840\n",
            "Epoch 248/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1616 - accuracy: 0.9364 - val_loss: 0.8490 - val_accuracy: 0.7860\n",
            "Epoch 249/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1582 - accuracy: 0.9379 - val_loss: 0.8513 - val_accuracy: 0.7910\n",
            "Epoch 250/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1618 - accuracy: 0.9345 - val_loss: 0.8323 - val_accuracy: 0.7860\n",
            "Epoch 251/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1602 - accuracy: 0.9364 - val_loss: 0.8317 - val_accuracy: 0.7780\n",
            "Epoch 252/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1570 - accuracy: 0.9383 - val_loss: 0.8655 - val_accuracy: 0.7840\n",
            "Epoch 253/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1643 - accuracy: 0.9330 - val_loss: 0.8163 - val_accuracy: 0.7810\n",
            "Epoch 254/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1580 - accuracy: 0.9361 - val_loss: 0.8540 - val_accuracy: 0.7750\n",
            "Epoch 255/1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1593 - accuracy: 0.9358 - val_loss: 0.8297 - val_accuracy: 0.7900\n",
            "Epoch 256/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1631 - accuracy: 0.9353 - val_loss: 0.8272 - val_accuracy: 0.7800\n",
            "Epoch 257/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1605 - accuracy: 0.9383 - val_loss: 0.8707 - val_accuracy: 0.7820\n",
            "Epoch 258/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1693 - accuracy: 0.9317 - val_loss: 0.8282 - val_accuracy: 0.7960\n",
            "Epoch 259/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1591 - accuracy: 0.9380 - val_loss: 0.8318 - val_accuracy: 0.7870\n",
            "Epoch 260/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1599 - accuracy: 0.9390 - val_loss: 0.8479 - val_accuracy: 0.7790\n",
            "Epoch 261/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1640 - accuracy: 0.9381 - val_loss: 0.8362 - val_accuracy: 0.7820\n",
            "Epoch 262/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1587 - accuracy: 0.9408 - val_loss: 0.8492 - val_accuracy: 0.7860\n",
            "Epoch 263/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1501 - accuracy: 0.9411 - val_loss: 0.8774 - val_accuracy: 0.7830\n",
            "Epoch 264/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1536 - accuracy: 0.9406 - val_loss: 0.8518 - val_accuracy: 0.7850\n",
            "Epoch 265/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1575 - accuracy: 0.9373 - val_loss: 0.8577 - val_accuracy: 0.7860\n",
            "Epoch 266/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1538 - accuracy: 0.9386 - val_loss: 0.8227 - val_accuracy: 0.7840\n",
            "Epoch 267/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1542 - accuracy: 0.9396 - val_loss: 0.8373 - val_accuracy: 0.7790\n",
            "Epoch 268/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1574 - accuracy: 0.9381 - val_loss: 0.8496 - val_accuracy: 0.7860\n",
            "Epoch 269/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1449 - accuracy: 0.9421 - val_loss: 0.8675 - val_accuracy: 0.7970\n",
            "Epoch 270/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1543 - accuracy: 0.9400 - val_loss: 0.8848 - val_accuracy: 0.7770\n",
            "Epoch 271/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1478 - accuracy: 0.9406 - val_loss: 0.8421 - val_accuracy: 0.7870\n",
            "Epoch 272/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1541 - accuracy: 0.9400 - val_loss: 0.8778 - val_accuracy: 0.7850\n",
            "Epoch 273/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1505 - accuracy: 0.9406 - val_loss: 0.8691 - val_accuracy: 0.7790\n",
            "Epoch 274/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1510 - accuracy: 0.9407 - val_loss: 0.8649 - val_accuracy: 0.7820\n",
            "Epoch 275/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1557 - accuracy: 0.9399 - val_loss: 0.9120 - val_accuracy: 0.7780\n",
            "Epoch 276/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1576 - accuracy: 0.9379 - val_loss: 0.8283 - val_accuracy: 0.7860\n",
            "Epoch 277/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1443 - accuracy: 0.9435 - val_loss: 0.8581 - val_accuracy: 0.7870\n",
            "Epoch 278/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1504 - accuracy: 0.9401 - val_loss: 0.8488 - val_accuracy: 0.7850\n",
            "Epoch 279/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1480 - accuracy: 0.9420 - val_loss: 0.9313 - val_accuracy: 0.7770\n",
            "Epoch 280/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1429 - accuracy: 0.9422 - val_loss: 0.8812 - val_accuracy: 0.7840\n",
            "Epoch 281/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1464 - accuracy: 0.9428 - val_loss: 0.8742 - val_accuracy: 0.7780\n",
            "Epoch 282/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1371 - accuracy: 0.9461 - val_loss: 0.9381 - val_accuracy: 0.7790\n",
            "Epoch 283/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1365 - accuracy: 0.9469 - val_loss: 0.9440 - val_accuracy: 0.7780\n",
            "Epoch 284/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1496 - accuracy: 0.9421 - val_loss: 0.8739 - val_accuracy: 0.7760\n",
            "Epoch 285/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1522 - accuracy: 0.9441 - val_loss: 0.8992 - val_accuracy: 0.7820\n",
            "Epoch 286/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1532 - accuracy: 0.9414 - val_loss: 0.9040 - val_accuracy: 0.7810\n",
            "Epoch 287/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1450 - accuracy: 0.9451 - val_loss: 0.9470 - val_accuracy: 0.7810\n",
            "Epoch 288/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1554 - accuracy: 0.9410 - val_loss: 0.9885 - val_accuracy: 0.7700\n",
            "Epoch 289/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1494 - accuracy: 0.9455 - val_loss: 0.8576 - val_accuracy: 0.7820\n",
            "Epoch 290/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1422 - accuracy: 0.9458 - val_loss: 0.9101 - val_accuracy: 0.7760\n",
            "Epoch 291/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1481 - accuracy: 0.9432 - val_loss: 0.8889 - val_accuracy: 0.7810\n",
            "Epoch 292/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1459 - accuracy: 0.9440 - val_loss: 0.9278 - val_accuracy: 0.7790\n",
            "Epoch 293/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1416 - accuracy: 0.9428 - val_loss: 0.9197 - val_accuracy: 0.7750\n",
            "Epoch 294/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1434 - accuracy: 0.9439 - val_loss: 0.9170 - val_accuracy: 0.7890\n",
            "Epoch 295/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1492 - accuracy: 0.9432 - val_loss: 0.8674 - val_accuracy: 0.7770\n",
            "Epoch 296/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1435 - accuracy: 0.9442 - val_loss: 0.9397 - val_accuracy: 0.7830\n",
            "Epoch 297/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1422 - accuracy: 0.9456 - val_loss: 0.9209 - val_accuracy: 0.7790\n",
            "Epoch 298/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1459 - accuracy: 0.9432 - val_loss: 0.9335 - val_accuracy: 0.7780\n",
            "Epoch 299/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1437 - accuracy: 0.9443 - val_loss: 0.8938 - val_accuracy: 0.7770\n",
            "Epoch 300/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1397 - accuracy: 0.9443 - val_loss: 0.9130 - val_accuracy: 0.7800\n",
            "Epoch 301/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1413 - accuracy: 0.9451 - val_loss: 0.9175 - val_accuracy: 0.7790\n",
            "Epoch 302/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1417 - accuracy: 0.9473 - val_loss: 0.9227 - val_accuracy: 0.7810\n",
            "Epoch 303/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1438 - accuracy: 0.9428 - val_loss: 0.8577 - val_accuracy: 0.7760\n",
            "Epoch 304/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1433 - accuracy: 0.9459 - val_loss: 0.8411 - val_accuracy: 0.7860\n",
            "Epoch 305/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1387 - accuracy: 0.9473 - val_loss: 0.9112 - val_accuracy: 0.7820\n",
            "Epoch 306/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1366 - accuracy: 0.9459 - val_loss: 0.9520 - val_accuracy: 0.7860\n",
            "Epoch 307/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1403 - accuracy: 0.9470 - val_loss: 0.9103 - val_accuracy: 0.7860\n",
            "Epoch 308/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1380 - accuracy: 0.9464 - val_loss: 0.9186 - val_accuracy: 0.7770\n",
            "Epoch 309/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1420 - accuracy: 0.9441 - val_loss: 0.8872 - val_accuracy: 0.7750\n",
            "Epoch 310/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1357 - accuracy: 0.9467 - val_loss: 0.9588 - val_accuracy: 0.7790\n",
            "Epoch 311/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1377 - accuracy: 0.9448 - val_loss: 0.9300 - val_accuracy: 0.7760\n",
            "Epoch 312/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1383 - accuracy: 0.9439 - val_loss: 0.8907 - val_accuracy: 0.7860\n",
            "Epoch 313/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1319 - accuracy: 0.9463 - val_loss: 0.9300 - val_accuracy: 0.7740\n",
            "Epoch 314/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1445 - accuracy: 0.9443 - val_loss: 0.9278 - val_accuracy: 0.7840\n",
            "Epoch 315/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1321 - accuracy: 0.9495 - val_loss: 0.9172 - val_accuracy: 0.7870\n",
            "Epoch 316/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1342 - accuracy: 0.9475 - val_loss: 0.9805 - val_accuracy: 0.7850\n",
            "Epoch 317/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1335 - accuracy: 0.9456 - val_loss: 1.0070 - val_accuracy: 0.7730\n",
            "Epoch 318/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1378 - accuracy: 0.9461 - val_loss: 0.9543 - val_accuracy: 0.7770\n",
            "Epoch 319/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1432 - accuracy: 0.9475 - val_loss: 0.9481 - val_accuracy: 0.7810\n",
            "Epoch 320/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1334 - accuracy: 0.9492 - val_loss: 0.9746 - val_accuracy: 0.7790\n",
            "Epoch 321/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1331 - accuracy: 0.9476 - val_loss: 0.9155 - val_accuracy: 0.7770\n",
            "Epoch 322/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1345 - accuracy: 0.9471 - val_loss: 0.8934 - val_accuracy: 0.7770\n",
            "Epoch 323/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1291 - accuracy: 0.9514 - val_loss: 0.9594 - val_accuracy: 0.7730\n",
            "Epoch 324/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1388 - accuracy: 0.9442 - val_loss: 0.9062 - val_accuracy: 0.7760\n",
            "Epoch 325/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1287 - accuracy: 0.9502 - val_loss: 0.9984 - val_accuracy: 0.7810\n",
            "Epoch 326/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1323 - accuracy: 0.9493 - val_loss: 0.9588 - val_accuracy: 0.7720\n",
            "Epoch 327/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1304 - accuracy: 0.9496 - val_loss: 0.9799 - val_accuracy: 0.7800\n",
            "Epoch 328/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1302 - accuracy: 0.9498 - val_loss: 0.9607 - val_accuracy: 0.7690\n",
            "Epoch 329/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1338 - accuracy: 0.9486 - val_loss: 0.9185 - val_accuracy: 0.7760\n",
            "Epoch 330/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1314 - accuracy: 0.9528 - val_loss: 0.9666 - val_accuracy: 0.7670\n",
            "Epoch 331/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1380 - accuracy: 0.9494 - val_loss: 0.9574 - val_accuracy: 0.7750\n",
            "Epoch 332/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1334 - accuracy: 0.9451 - val_loss: 0.9428 - val_accuracy: 0.7720\n",
            "Epoch 333/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1258 - accuracy: 0.9549 - val_loss: 0.9744 - val_accuracy: 0.7810\n",
            "Epoch 334/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1348 - accuracy: 0.9477 - val_loss: 0.9899 - val_accuracy: 0.7700\n",
            "Epoch 335/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1317 - accuracy: 0.9496 - val_loss: 0.9969 - val_accuracy: 0.7690\n",
            "Epoch 336/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1324 - accuracy: 0.9491 - val_loss: 0.9955 - val_accuracy: 0.7660\n",
            "Epoch 337/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1293 - accuracy: 0.9507 - val_loss: 0.9969 - val_accuracy: 0.7800\n",
            "Epoch 338/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1332 - accuracy: 0.9477 - val_loss: 1.1058 - val_accuracy: 0.7680\n",
            "Epoch 339/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1328 - accuracy: 0.9494 - val_loss: 0.9602 - val_accuracy: 0.7680\n",
            "Epoch 340/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1336 - accuracy: 0.9499 - val_loss: 0.8935 - val_accuracy: 0.7760\n",
            "Epoch 341/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1223 - accuracy: 0.9499 - val_loss: 0.9914 - val_accuracy: 0.7800\n",
            "Epoch 342/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1221 - accuracy: 0.9542 - val_loss: 1.0276 - val_accuracy: 0.7820\n",
            "Epoch 343/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1329 - accuracy: 0.9518 - val_loss: 1.0408 - val_accuracy: 0.7770\n",
            "Epoch 344/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1363 - accuracy: 0.9488 - val_loss: 0.9801 - val_accuracy: 0.7760\n",
            "Epoch 345/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1286 - accuracy: 0.9508 - val_loss: 0.9682 - val_accuracy: 0.7750\n",
            "Epoch 346/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1287 - accuracy: 0.9517 - val_loss: 0.9691 - val_accuracy: 0.7690\n",
            "Epoch 347/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1217 - accuracy: 0.9531 - val_loss: 1.0048 - val_accuracy: 0.7690\n",
            "Epoch 348/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1286 - accuracy: 0.9508 - val_loss: 1.0136 - val_accuracy: 0.7730\n",
            "Epoch 349/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1300 - accuracy: 0.9511 - val_loss: 1.0374 - val_accuracy: 0.7740\n",
            "Epoch 350/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1280 - accuracy: 0.9530 - val_loss: 1.0187 - val_accuracy: 0.7730\n",
            "Epoch 351/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1330 - accuracy: 0.9521 - val_loss: 1.0511 - val_accuracy: 0.7730\n",
            "Epoch 352/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1330 - accuracy: 0.9491 - val_loss: 0.9513 - val_accuracy: 0.7830\n",
            "Epoch 353/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1240 - accuracy: 0.9532 - val_loss: 1.0096 - val_accuracy: 0.7830\n",
            "Epoch 354/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1254 - accuracy: 0.9534 - val_loss: 1.0769 - val_accuracy: 0.7790\n",
            "Epoch 355/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1168 - accuracy: 0.9555 - val_loss: 1.1304 - val_accuracy: 0.7680\n",
            "Epoch 356/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1202 - accuracy: 0.9550 - val_loss: 1.0848 - val_accuracy: 0.7780\n",
            "Epoch 357/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1276 - accuracy: 0.9521 - val_loss: 1.0016 - val_accuracy: 0.7710\n",
            "Epoch 358/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1247 - accuracy: 0.9535 - val_loss: 1.0466 - val_accuracy: 0.7680\n",
            "Epoch 359/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1234 - accuracy: 0.9559 - val_loss: 1.0216 - val_accuracy: 0.7720\n",
            "Epoch 360/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1204 - accuracy: 0.9568 - val_loss: 1.0152 - val_accuracy: 0.7770\n",
            "Epoch 361/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1126 - accuracy: 0.9598 - val_loss: 1.0768 - val_accuracy: 0.7720\n",
            "Epoch 362/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1288 - accuracy: 0.9555 - val_loss: 1.0325 - val_accuracy: 0.7750\n",
            "Epoch 363/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1242 - accuracy: 0.9518 - val_loss: 0.9975 - val_accuracy: 0.7710\n",
            "Epoch 364/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1296 - accuracy: 0.9525 - val_loss: 1.0129 - val_accuracy: 0.7700\n",
            "Epoch 365/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1207 - accuracy: 0.9555 - val_loss: 1.1061 - val_accuracy: 0.7740\n",
            "Epoch 366/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1249 - accuracy: 0.9538 - val_loss: 1.0562 - val_accuracy: 0.7780\n",
            "Epoch 367/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1222 - accuracy: 0.9521 - val_loss: 1.1104 - val_accuracy: 0.7740\n",
            "Epoch 368/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1257 - accuracy: 0.9537 - val_loss: 1.0394 - val_accuracy: 0.7740\n",
            "Epoch 369/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1283 - accuracy: 0.9545 - val_loss: 0.9825 - val_accuracy: 0.7600\n",
            "Epoch 370/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1220 - accuracy: 0.9556 - val_loss: 1.0835 - val_accuracy: 0.7670\n",
            "Epoch 371/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1236 - accuracy: 0.9543 - val_loss: 1.0971 - val_accuracy: 0.7710\n",
            "Epoch 372/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1198 - accuracy: 0.9556 - val_loss: 1.0139 - val_accuracy: 0.7640\n",
            "Epoch 373/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1307 - accuracy: 0.9522 - val_loss: 1.0904 - val_accuracy: 0.7740\n",
            "Epoch 374/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1165 - accuracy: 0.9568 - val_loss: 0.9903 - val_accuracy: 0.7720\n",
            "Epoch 375/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1249 - accuracy: 0.9517 - val_loss: 0.9994 - val_accuracy: 0.7730\n",
            "Epoch 376/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1218 - accuracy: 0.9548 - val_loss: 1.0407 - val_accuracy: 0.7700\n",
            "Epoch 377/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1235 - accuracy: 0.9542 - val_loss: 1.1282 - val_accuracy: 0.7670\n",
            "Epoch 378/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1238 - accuracy: 0.9566 - val_loss: 1.0338 - val_accuracy: 0.7720\n",
            "Epoch 379/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1185 - accuracy: 0.9523 - val_loss: 1.0238 - val_accuracy: 0.7870\n",
            "Epoch 380/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1228 - accuracy: 0.9545 - val_loss: 1.0777 - val_accuracy: 0.7660\n",
            "Epoch 381/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1134 - accuracy: 0.9568 - val_loss: 1.1096 - val_accuracy: 0.7640\n",
            "Epoch 382/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1214 - accuracy: 0.9527 - val_loss: 1.0682 - val_accuracy: 0.7620\n",
            "Epoch 383/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1121 - accuracy: 0.9588 - val_loss: 1.1030 - val_accuracy: 0.7710\n",
            "Epoch 384/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1225 - accuracy: 0.9566 - val_loss: 1.1297 - val_accuracy: 0.7690\n",
            "Epoch 385/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1158 - accuracy: 0.9553 - val_loss: 1.0994 - val_accuracy: 0.7680\n",
            "Epoch 386/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1122 - accuracy: 0.9599 - val_loss: 1.0798 - val_accuracy: 0.7600\n",
            "Epoch 387/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1250 - accuracy: 0.9523 - val_loss: 1.0859 - val_accuracy: 0.7830\n",
            "Epoch 388/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1170 - accuracy: 0.9566 - val_loss: 1.0566 - val_accuracy: 0.7610\n",
            "Epoch 389/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1078 - accuracy: 0.9618 - val_loss: 1.0441 - val_accuracy: 0.7700\n",
            "Epoch 390/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1165 - accuracy: 0.9572 - val_loss: 1.0316 - val_accuracy: 0.7660\n",
            "Epoch 391/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1137 - accuracy: 0.9561 - val_loss: 1.0448 - val_accuracy: 0.7770\n",
            "Epoch 392/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1160 - accuracy: 0.9544 - val_loss: 1.1524 - val_accuracy: 0.7620\n",
            "Epoch 393/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1138 - accuracy: 0.9572 - val_loss: 1.1526 - val_accuracy: 0.7560\n",
            "Epoch 394/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1167 - accuracy: 0.9556 - val_loss: 1.1160 - val_accuracy: 0.7640\n",
            "Epoch 395/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1139 - accuracy: 0.9593 - val_loss: 1.1326 - val_accuracy: 0.7720\n",
            "Epoch 396/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1173 - accuracy: 0.9580 - val_loss: 1.0858 - val_accuracy: 0.7640\n",
            "Epoch 397/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1166 - accuracy: 0.9585 - val_loss: 1.1541 - val_accuracy: 0.7660\n",
            "Epoch 398/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1157 - accuracy: 0.9579 - val_loss: 1.0531 - val_accuracy: 0.7580\n",
            "Epoch 399/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1162 - accuracy: 0.9569 - val_loss: 1.1211 - val_accuracy: 0.7590\n",
            "Epoch 400/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1204 - accuracy: 0.9584 - val_loss: 1.0630 - val_accuracy: 0.7690\n",
            "Epoch 401/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1131 - accuracy: 0.9578 - val_loss: 1.0939 - val_accuracy: 0.7710\n",
            "Epoch 402/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1164 - accuracy: 0.9563 - val_loss: 1.1562 - val_accuracy: 0.7590\n",
            "Epoch 403/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1135 - accuracy: 0.9585 - val_loss: 1.1645 - val_accuracy: 0.7580\n",
            "Epoch 404/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1198 - accuracy: 0.9552 - val_loss: 1.1119 - val_accuracy: 0.7670\n",
            "Epoch 405/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1075 - accuracy: 0.9580 - val_loss: 1.2844 - val_accuracy: 0.7560\n",
            "Epoch 406/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1132 - accuracy: 0.9558 - val_loss: 1.0827 - val_accuracy: 0.7690\n",
            "Epoch 407/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1143 - accuracy: 0.9574 - val_loss: 1.1457 - val_accuracy: 0.7610\n",
            "Epoch 408/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1096 - accuracy: 0.9576 - val_loss: 1.1691 - val_accuracy: 0.7730\n",
            "Epoch 409/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1143 - accuracy: 0.9562 - val_loss: 1.1233 - val_accuracy: 0.7670\n",
            "Epoch 410/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1159 - accuracy: 0.9588 - val_loss: 1.1086 - val_accuracy: 0.7720\n",
            "Epoch 411/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1107 - accuracy: 0.9604 - val_loss: 1.1460 - val_accuracy: 0.7710\n",
            "Epoch 412/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1076 - accuracy: 0.9591 - val_loss: 1.1784 - val_accuracy: 0.7630\n",
            "Epoch 413/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1077 - accuracy: 0.9606 - val_loss: 1.1272 - val_accuracy: 0.7700\n",
            "Epoch 414/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1122 - accuracy: 0.9561 - val_loss: 1.1394 - val_accuracy: 0.7740\n",
            "Epoch 415/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1121 - accuracy: 0.9576 - val_loss: 1.1765 - val_accuracy: 0.7670\n",
            "Epoch 416/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1124 - accuracy: 0.9577 - val_loss: 1.2093 - val_accuracy: 0.7590\n",
            "Epoch 417/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1175 - accuracy: 0.9567 - val_loss: 1.1858 - val_accuracy: 0.7730\n",
            "Epoch 418/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1092 - accuracy: 0.9598 - val_loss: 1.2145 - val_accuracy: 0.7720\n",
            "Epoch 419/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1240 - accuracy: 0.9549 - val_loss: 1.1015 - val_accuracy: 0.7650\n",
            "Epoch 420/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1122 - accuracy: 0.9592 - val_loss: 1.0806 - val_accuracy: 0.7740\n",
            "Epoch 421/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1125 - accuracy: 0.9576 - val_loss: 1.1221 - val_accuracy: 0.7670\n",
            "Epoch 422/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1112 - accuracy: 0.9579 - val_loss: 1.1601 - val_accuracy: 0.7670\n",
            "Epoch 423/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1064 - accuracy: 0.9591 - val_loss: 1.1600 - val_accuracy: 0.7700\n",
            "Epoch 424/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1143 - accuracy: 0.9563 - val_loss: 1.2064 - val_accuracy: 0.7700\n",
            "Epoch 425/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1132 - accuracy: 0.9583 - val_loss: 1.1801 - val_accuracy: 0.7740\n",
            "Epoch 426/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1071 - accuracy: 0.9613 - val_loss: 1.2271 - val_accuracy: 0.7610\n",
            "Epoch 427/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1120 - accuracy: 0.9587 - val_loss: 1.1956 - val_accuracy: 0.7670\n",
            "Epoch 428/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1111 - accuracy: 0.9545 - val_loss: 1.1767 - val_accuracy: 0.7690\n",
            "Epoch 429/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1135 - accuracy: 0.9583 - val_loss: 1.1720 - val_accuracy: 0.7630\n",
            "Epoch 430/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1104 - accuracy: 0.9583 - val_loss: 1.2736 - val_accuracy: 0.7630\n",
            "Epoch 431/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1117 - accuracy: 0.9570 - val_loss: 1.2398 - val_accuracy: 0.7570\n",
            "Epoch 432/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1099 - accuracy: 0.9605 - val_loss: 1.1527 - val_accuracy: 0.7590\n",
            "Epoch 433/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1117 - accuracy: 0.9586 - val_loss: 1.1595 - val_accuracy: 0.7590\n",
            "Epoch 434/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1099 - accuracy: 0.9589 - val_loss: 1.0784 - val_accuracy: 0.7720\n",
            "Epoch 435/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1138 - accuracy: 0.9568 - val_loss: 1.1215 - val_accuracy: 0.7710\n",
            "Epoch 436/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1089 - accuracy: 0.9609 - val_loss: 1.1899 - val_accuracy: 0.7730\n",
            "Epoch 437/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1113 - accuracy: 0.9570 - val_loss: 1.0927 - val_accuracy: 0.7670\n",
            "Epoch 438/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1053 - accuracy: 0.9592 - val_loss: 1.2126 - val_accuracy: 0.7700\n",
            "Epoch 439/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1084 - accuracy: 0.9587 - val_loss: 1.2252 - val_accuracy: 0.7660\n",
            "Epoch 440/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1168 - accuracy: 0.9578 - val_loss: 1.0926 - val_accuracy: 0.7700\n",
            "Epoch 441/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1037 - accuracy: 0.9618 - val_loss: 1.2002 - val_accuracy: 0.7630\n",
            "Epoch 442/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 1.1783 - val_accuracy: 0.7670\n",
            "Epoch 443/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1056 - accuracy: 0.9604 - val_loss: 1.1961 - val_accuracy: 0.7650\n",
            "Epoch 444/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1071 - accuracy: 0.9600 - val_loss: 1.1699 - val_accuracy: 0.7670\n",
            "Epoch 445/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1065 - accuracy: 0.9613 - val_loss: 1.1404 - val_accuracy: 0.7630\n",
            "Epoch 446/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1109 - accuracy: 0.9604 - val_loss: 1.1080 - val_accuracy: 0.7760\n",
            "Epoch 447/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1068 - accuracy: 0.9614 - val_loss: 1.1327 - val_accuracy: 0.7670\n",
            "Epoch 448/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1120 - accuracy: 0.9592 - val_loss: 1.1585 - val_accuracy: 0.7610\n",
            "Epoch 449/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1034 - accuracy: 0.9641 - val_loss: 1.2434 - val_accuracy: 0.7650\n",
            "Epoch 450/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1090 - accuracy: 0.9596 - val_loss: 1.1352 - val_accuracy: 0.7650\n",
            "Epoch 451/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1065 - accuracy: 0.9605 - val_loss: 1.2328 - val_accuracy: 0.7520\n",
            "Epoch 452/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1093 - accuracy: 0.9590 - val_loss: 1.1705 - val_accuracy: 0.7650\n",
            "Epoch 453/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 1.1666 - val_accuracy: 0.7650\n",
            "Epoch 454/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1080 - accuracy: 0.9594 - val_loss: 1.2051 - val_accuracy: 0.7600\n",
            "Epoch 455/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1033 - accuracy: 0.9622 - val_loss: 1.2098 - val_accuracy: 0.7660\n",
            "Epoch 456/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1027 - accuracy: 0.9600 - val_loss: 1.2479 - val_accuracy: 0.7670\n",
            "Epoch 457/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1110 - accuracy: 0.9592 - val_loss: 1.2022 - val_accuracy: 0.7590\n",
            "Epoch 458/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 1.2847 - val_accuracy: 0.7710\n",
            "Epoch 459/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1095 - accuracy: 0.9613 - val_loss: 1.2189 - val_accuracy: 0.7590\n",
            "Epoch 460/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0984 - accuracy: 0.9635 - val_loss: 1.1996 - val_accuracy: 0.7700\n",
            "Epoch 461/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1097 - accuracy: 0.9606 - val_loss: 1.2188 - val_accuracy: 0.7640\n",
            "Epoch 462/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1002 - accuracy: 0.9633 - val_loss: 1.1942 - val_accuracy: 0.7760\n",
            "Epoch 463/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1029 - accuracy: 0.9615 - val_loss: 1.2211 - val_accuracy: 0.7750\n",
            "Epoch 464/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 1.2441 - val_accuracy: 0.7660\n",
            "Epoch 465/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1016 - accuracy: 0.9629 - val_loss: 1.3295 - val_accuracy: 0.7760\n",
            "Epoch 466/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1020 - accuracy: 0.9637 - val_loss: 1.2471 - val_accuracy: 0.7650\n",
            "Epoch 467/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1059 - accuracy: 0.9608 - val_loss: 1.2293 - val_accuracy: 0.7750\n",
            "Epoch 468/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1075 - accuracy: 0.9594 - val_loss: 1.2791 - val_accuracy: 0.7750\n",
            "Epoch 469/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0966 - accuracy: 0.9646 - val_loss: 1.2469 - val_accuracy: 0.7700\n",
            "Epoch 470/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0999 - accuracy: 0.9629 - val_loss: 1.2524 - val_accuracy: 0.7630\n",
            "Epoch 471/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1081 - accuracy: 0.9582 - val_loss: 1.2202 - val_accuracy: 0.7630\n",
            "Epoch 472/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1093 - accuracy: 0.9601 - val_loss: 1.2282 - val_accuracy: 0.7710\n",
            "Epoch 473/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1014 - accuracy: 0.9617 - val_loss: 1.2607 - val_accuracy: 0.7710\n",
            "Epoch 474/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1050 - accuracy: 0.9624 - val_loss: 1.2188 - val_accuracy: 0.7710\n",
            "Epoch 475/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1061 - accuracy: 0.9619 - val_loss: 1.2919 - val_accuracy: 0.7660\n",
            "Epoch 476/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1016 - accuracy: 0.9650 - val_loss: 1.2186 - val_accuracy: 0.7700\n",
            "Epoch 477/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1070 - accuracy: 0.9628 - val_loss: 1.2829 - val_accuracy: 0.7710\n",
            "Epoch 478/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1008 - accuracy: 0.9622 - val_loss: 1.2965 - val_accuracy: 0.7640\n",
            "Epoch 479/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1025 - accuracy: 0.9624 - val_loss: 1.2539 - val_accuracy: 0.7630\n",
            "Epoch 480/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0945 - accuracy: 0.9654 - val_loss: 1.2951 - val_accuracy: 0.7620\n",
            "Epoch 481/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0994 - accuracy: 0.9617 - val_loss: 1.3294 - val_accuracy: 0.7650\n",
            "Epoch 482/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0958 - accuracy: 0.9647 - val_loss: 1.3374 - val_accuracy: 0.7640\n",
            "Epoch 483/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1115 - accuracy: 0.9604 - val_loss: 1.2716 - val_accuracy: 0.7730\n",
            "Epoch 484/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1031 - accuracy: 0.9636 - val_loss: 1.2516 - val_accuracy: 0.7680\n",
            "Epoch 485/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1028 - accuracy: 0.9624 - val_loss: 1.1680 - val_accuracy: 0.7600\n",
            "Epoch 486/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1019 - accuracy: 0.9655 - val_loss: 1.2467 - val_accuracy: 0.7650\n",
            "Epoch 487/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1085 - accuracy: 0.9624 - val_loss: 1.2493 - val_accuracy: 0.7660\n",
            "Epoch 488/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0988 - accuracy: 0.9638 - val_loss: 1.2372 - val_accuracy: 0.7700\n",
            "Epoch 489/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0991 - accuracy: 0.9656 - val_loss: 1.2974 - val_accuracy: 0.7640\n",
            "Epoch 490/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0967 - accuracy: 0.9640 - val_loss: 1.2953 - val_accuracy: 0.7660\n",
            "Epoch 491/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1071 - accuracy: 0.9622 - val_loss: 1.1838 - val_accuracy: 0.7790\n",
            "Epoch 492/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0990 - accuracy: 0.9628 - val_loss: 1.2200 - val_accuracy: 0.7650\n",
            "Epoch 493/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0999 - accuracy: 0.9647 - val_loss: 1.2334 - val_accuracy: 0.7660\n",
            "Epoch 494/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1031 - accuracy: 0.9631 - val_loss: 1.2149 - val_accuracy: 0.7710\n",
            "Epoch 495/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1054 - accuracy: 0.9619 - val_loss: 1.2282 - val_accuracy: 0.7630\n",
            "Epoch 496/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0976 - accuracy: 0.9640 - val_loss: 1.1932 - val_accuracy: 0.7710\n",
            "Epoch 497/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1010 - accuracy: 0.9635 - val_loss: 1.2865 - val_accuracy: 0.7690\n",
            "Epoch 498/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1016 - accuracy: 0.9632 - val_loss: 1.1924 - val_accuracy: 0.7740\n",
            "Epoch 499/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1027 - accuracy: 0.9611 - val_loss: 1.2065 - val_accuracy: 0.7720\n",
            "Epoch 500/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0960 - accuracy: 0.9641 - val_loss: 1.2725 - val_accuracy: 0.7700\n",
            "Epoch 501/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1028 - accuracy: 0.9635 - val_loss: 1.2493 - val_accuracy: 0.7710\n",
            "Epoch 502/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0993 - accuracy: 0.9638 - val_loss: 1.2570 - val_accuracy: 0.7780\n",
            "Epoch 503/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0982 - accuracy: 0.9645 - val_loss: 1.1837 - val_accuracy: 0.7780\n",
            "Epoch 504/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1031 - accuracy: 0.9637 - val_loss: 1.2630 - val_accuracy: 0.7660\n",
            "Epoch 505/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1024 - accuracy: 0.9642 - val_loss: 1.2764 - val_accuracy: 0.7690\n",
            "Epoch 506/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0957 - accuracy: 0.9654 - val_loss: 1.2254 - val_accuracy: 0.7630\n",
            "Epoch 507/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1025 - accuracy: 0.9639 - val_loss: 1.2864 - val_accuracy: 0.7700\n",
            "Epoch 508/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1009 - accuracy: 0.9645 - val_loss: 1.2208 - val_accuracy: 0.7700\n",
            "Epoch 509/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0980 - accuracy: 0.9666 - val_loss: 1.2297 - val_accuracy: 0.7710\n",
            "Epoch 510/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0943 - accuracy: 0.9653 - val_loss: 1.3372 - val_accuracy: 0.7730\n",
            "Epoch 511/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0989 - accuracy: 0.9624 - val_loss: 1.3389 - val_accuracy: 0.7590\n",
            "Epoch 512/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1008 - accuracy: 0.9635 - val_loss: 1.2533 - val_accuracy: 0.7660\n",
            "Epoch 513/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0961 - accuracy: 0.9668 - val_loss: 1.3629 - val_accuracy: 0.7630\n",
            "Epoch 514/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1032 - accuracy: 0.9639 - val_loss: 1.2627 - val_accuracy: 0.7660\n",
            "Epoch 515/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1003 - accuracy: 0.9658 - val_loss: 1.3501 - val_accuracy: 0.7610\n",
            "Epoch 516/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0972 - accuracy: 0.9659 - val_loss: 1.3109 - val_accuracy: 0.7660\n",
            "Epoch 517/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0940 - accuracy: 0.9646 - val_loss: 1.3271 - val_accuracy: 0.7690\n",
            "Epoch 518/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0964 - accuracy: 0.9622 - val_loss: 1.2886 - val_accuracy: 0.7770\n",
            "Epoch 519/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1010 - accuracy: 0.9650 - val_loss: 1.2362 - val_accuracy: 0.7650\n",
            "Epoch 520/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1064 - accuracy: 0.9647 - val_loss: 1.2498 - val_accuracy: 0.7620\n",
            "Epoch 521/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1013 - accuracy: 0.9644 - val_loss: 1.2329 - val_accuracy: 0.7610\n",
            "Epoch 522/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0995 - accuracy: 0.9661 - val_loss: 1.2530 - val_accuracy: 0.7590\n",
            "Epoch 523/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0938 - accuracy: 0.9680 - val_loss: 1.3019 - val_accuracy: 0.7630\n",
            "Epoch 524/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1010 - accuracy: 0.9627 - val_loss: 1.1942 - val_accuracy: 0.7670\n",
            "Epoch 525/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1033 - accuracy: 0.9645 - val_loss: 1.2711 - val_accuracy: 0.7660\n",
            "Epoch 526/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0904 - accuracy: 0.9650 - val_loss: 1.2947 - val_accuracy: 0.7700\n",
            "Epoch 527/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0994 - accuracy: 0.9642 - val_loss: 1.3016 - val_accuracy: 0.7720\n",
            "Epoch 528/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0941 - accuracy: 0.9675 - val_loss: 1.3184 - val_accuracy: 0.7640\n",
            "Epoch 529/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0914 - accuracy: 0.9676 - val_loss: 1.4020 - val_accuracy: 0.7610\n",
            "Epoch 530/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0929 - accuracy: 0.9653 - val_loss: 1.3609 - val_accuracy: 0.7600\n",
            "Epoch 531/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 1.3046 - val_accuracy: 0.7620\n",
            "Epoch 532/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0989 - accuracy: 0.9653 - val_loss: 1.3061 - val_accuracy: 0.7700\n",
            "Epoch 533/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 1.2369 - val_accuracy: 0.7680\n",
            "Epoch 534/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0927 - accuracy: 0.9683 - val_loss: 1.2861 - val_accuracy: 0.7680\n",
            "Epoch 535/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0926 - accuracy: 0.9671 - val_loss: 1.2569 - val_accuracy: 0.7720\n",
            "Epoch 536/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0991 - accuracy: 0.9633 - val_loss: 1.3119 - val_accuracy: 0.7650\n",
            "Epoch 537/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 1.2326 - val_accuracy: 0.7690\n",
            "Epoch 538/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 1.2817 - val_accuracy: 0.7760\n",
            "Epoch 539/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0920 - accuracy: 0.9677 - val_loss: 1.2549 - val_accuracy: 0.7750\n",
            "Epoch 540/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1021 - accuracy: 0.9637 - val_loss: 1.2282 - val_accuracy: 0.7650\n",
            "Epoch 541/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1010 - accuracy: 0.9623 - val_loss: 1.2931 - val_accuracy: 0.7640\n",
            "Epoch 542/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 1.2924 - val_accuracy: 0.7600\n",
            "Epoch 543/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1107 - accuracy: 0.9614 - val_loss: 1.2382 - val_accuracy: 0.7620\n",
            "Epoch 544/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0970 - accuracy: 0.9661 - val_loss: 1.2335 - val_accuracy: 0.7630\n",
            "Epoch 545/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 1.3289 - val_accuracy: 0.7770\n",
            "Epoch 546/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0933 - accuracy: 0.9676 - val_loss: 1.3016 - val_accuracy: 0.7680\n",
            "Epoch 547/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0959 - accuracy: 0.9682 - val_loss: 1.3061 - val_accuracy: 0.7740\n",
            "Epoch 548/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1007 - accuracy: 0.9629 - val_loss: 1.3325 - val_accuracy: 0.7620\n",
            "Epoch 549/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0996 - accuracy: 0.9646 - val_loss: 1.2374 - val_accuracy: 0.7690\n",
            "Epoch 550/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0970 - accuracy: 0.9635 - val_loss: 1.3192 - val_accuracy: 0.7650\n",
            "Epoch 551/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0929 - accuracy: 0.9672 - val_loss: 1.3139 - val_accuracy: 0.7550\n",
            "Epoch 552/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0956 - accuracy: 0.9665 - val_loss: 1.2965 - val_accuracy: 0.7570\n",
            "Epoch 553/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0888 - accuracy: 0.9676 - val_loss: 1.2805 - val_accuracy: 0.7620\n",
            "Epoch 554/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0985 - accuracy: 0.9633 - val_loss: 1.2859 - val_accuracy: 0.7640\n",
            "Epoch 555/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0928 - accuracy: 0.9651 - val_loss: 1.2128 - val_accuracy: 0.7710\n",
            "Epoch 556/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0957 - accuracy: 0.9670 - val_loss: 1.3032 - val_accuracy: 0.7690\n",
            "Epoch 557/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1009 - accuracy: 0.9658 - val_loss: 1.2905 - val_accuracy: 0.7630\n",
            "Epoch 558/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0990 - accuracy: 0.9642 - val_loss: 1.3290 - val_accuracy: 0.7610\n",
            "Epoch 559/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1032 - accuracy: 0.9644 - val_loss: 1.2504 - val_accuracy: 0.7700\n",
            "Epoch 560/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0945 - accuracy: 0.9676 - val_loss: 1.2694 - val_accuracy: 0.7720\n",
            "Epoch 561/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1002 - accuracy: 0.9628 - val_loss: 1.2591 - val_accuracy: 0.7650\n",
            "Epoch 562/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1024 - accuracy: 0.9637 - val_loss: 1.2557 - val_accuracy: 0.7620\n",
            "Epoch 563/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0920 - accuracy: 0.9665 - val_loss: 1.2249 - val_accuracy: 0.7660\n",
            "Epoch 564/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0934 - accuracy: 0.9660 - val_loss: 1.2503 - val_accuracy: 0.7640\n",
            "Epoch 565/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0927 - accuracy: 0.9672 - val_loss: 1.2628 - val_accuracy: 0.7730\n",
            "Epoch 566/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0957 - accuracy: 0.9661 - val_loss: 1.3560 - val_accuracy: 0.7760\n",
            "Epoch 567/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0894 - accuracy: 0.9690 - val_loss: 1.2551 - val_accuracy: 0.7690\n",
            "Epoch 568/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0912 - accuracy: 0.9672 - val_loss: 1.3426 - val_accuracy: 0.7630\n",
            "Epoch 569/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0985 - accuracy: 0.9637 - val_loss: 1.2930 - val_accuracy: 0.7620\n",
            "Epoch 570/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0928 - accuracy: 0.9691 - val_loss: 1.3694 - val_accuracy: 0.7620\n",
            "Epoch 571/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0906 - accuracy: 0.9664 - val_loss: 1.3622 - val_accuracy: 0.7670\n",
            "Epoch 572/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1005 - accuracy: 0.9678 - val_loss: 1.2812 - val_accuracy: 0.7620\n",
            "Epoch 573/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0966 - accuracy: 0.9685 - val_loss: 1.2791 - val_accuracy: 0.7680\n",
            "Epoch 574/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0950 - accuracy: 0.9671 - val_loss: 1.2908 - val_accuracy: 0.7550\n",
            "Epoch 575/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 1.2379 - val_accuracy: 0.7650\n",
            "Epoch 576/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0945 - accuracy: 0.9656 - val_loss: 1.3548 - val_accuracy: 0.7570\n",
            "Epoch 577/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0910 - accuracy: 0.9685 - val_loss: 1.3309 - val_accuracy: 0.7580\n",
            "Epoch 578/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0999 - accuracy: 0.9654 - val_loss: 1.2933 - val_accuracy: 0.7750\n",
            "Epoch 579/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 1.2819 - val_accuracy: 0.7670\n",
            "Epoch 580/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 1.2686 - val_accuracy: 0.7750\n",
            "Epoch 581/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0884 - accuracy: 0.9687 - val_loss: 1.3246 - val_accuracy: 0.7680\n",
            "Epoch 582/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0845 - accuracy: 0.9689 - val_loss: 1.4011 - val_accuracy: 0.7730\n",
            "Epoch 583/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0837 - accuracy: 0.9690 - val_loss: 1.3772 - val_accuracy: 0.7630\n",
            "Epoch 584/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0957 - accuracy: 0.9663 - val_loss: 1.3156 - val_accuracy: 0.7730\n",
            "Epoch 585/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0947 - accuracy: 0.9672 - val_loss: 1.2800 - val_accuracy: 0.7610\n",
            "Epoch 586/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0921 - accuracy: 0.9688 - val_loss: 1.3303 - val_accuracy: 0.7650\n",
            "Epoch 587/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 1.2526 - val_accuracy: 0.7710\n",
            "Epoch 588/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0965 - accuracy: 0.9679 - val_loss: 1.2911 - val_accuracy: 0.7640\n",
            "Epoch 589/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0887 - accuracy: 0.9679 - val_loss: 1.3819 - val_accuracy: 0.7620\n",
            "Epoch 590/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 1.2425 - val_accuracy: 0.7670\n",
            "Epoch 591/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0982 - accuracy: 0.9660 - val_loss: 1.2346 - val_accuracy: 0.7570\n",
            "Epoch 592/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0937 - accuracy: 0.9671 - val_loss: 1.3055 - val_accuracy: 0.7620\n",
            "Epoch 593/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0909 - accuracy: 0.9690 - val_loss: 1.3017 - val_accuracy: 0.7560\n",
            "Epoch 594/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0930 - accuracy: 0.9669 - val_loss: 1.2515 - val_accuracy: 0.7600\n",
            "Epoch 595/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0905 - accuracy: 0.9657 - val_loss: 1.3005 - val_accuracy: 0.7680\n",
            "Epoch 596/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0911 - accuracy: 0.9690 - val_loss: 1.4095 - val_accuracy: 0.7670\n",
            "Epoch 597/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0894 - accuracy: 0.9683 - val_loss: 1.4017 - val_accuracy: 0.7740\n",
            "Epoch 598/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0934 - accuracy: 0.9668 - val_loss: 1.2322 - val_accuracy: 0.7750\n",
            "Epoch 599/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0946 - accuracy: 0.9676 - val_loss: 1.2492 - val_accuracy: 0.7640\n",
            "Epoch 600/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0905 - accuracy: 0.9675 - val_loss: 1.2076 - val_accuracy: 0.7780\n",
            "Epoch 601/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0934 - accuracy: 0.9659 - val_loss: 1.2649 - val_accuracy: 0.7730\n",
            "Epoch 602/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0900 - accuracy: 0.9659 - val_loss: 1.2433 - val_accuracy: 0.7740\n",
            "Epoch 603/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0928 - accuracy: 0.9675 - val_loss: 1.2788 - val_accuracy: 0.7690\n",
            "Epoch 604/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0881 - accuracy: 0.9682 - val_loss: 1.4877 - val_accuracy: 0.7630\n",
            "Epoch 605/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0914 - accuracy: 0.9679 - val_loss: 1.2769 - val_accuracy: 0.7750\n",
            "Epoch 606/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0908 - accuracy: 0.9684 - val_loss: 1.3181 - val_accuracy: 0.7670\n",
            "Epoch 607/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0884 - accuracy: 0.9692 - val_loss: 1.2735 - val_accuracy: 0.7740\n",
            "Epoch 608/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0880 - accuracy: 0.9648 - val_loss: 1.2795 - val_accuracy: 0.7650\n",
            "Epoch 609/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0802 - accuracy: 0.9702 - val_loss: 1.4146 - val_accuracy: 0.7730\n",
            "Epoch 610/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0983 - accuracy: 0.9683 - val_loss: 1.1820 - val_accuracy: 0.7820\n",
            "Epoch 611/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0977 - accuracy: 0.9669 - val_loss: 1.2817 - val_accuracy: 0.7630\n",
            "Epoch 612/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0970 - accuracy: 0.9673 - val_loss: 1.3504 - val_accuracy: 0.7760\n",
            "Epoch 613/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0882 - accuracy: 0.9679 - val_loss: 1.3550 - val_accuracy: 0.7670\n",
            "Epoch 614/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0906 - accuracy: 0.9689 - val_loss: 1.2331 - val_accuracy: 0.7690\n",
            "Epoch 615/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0923 - accuracy: 0.9680 - val_loss: 1.1932 - val_accuracy: 0.7680\n",
            "Epoch 616/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1003 - accuracy: 0.9654 - val_loss: 1.2246 - val_accuracy: 0.7700\n",
            "Epoch 617/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0943 - accuracy: 0.9676 - val_loss: 1.2475 - val_accuracy: 0.7650\n",
            "Epoch 618/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0853 - accuracy: 0.9716 - val_loss: 1.3924 - val_accuracy: 0.7670\n",
            "Epoch 619/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0890 - accuracy: 0.9704 - val_loss: 1.3264 - val_accuracy: 0.7820\n",
            "Epoch 620/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 1.2563 - val_accuracy: 0.7650\n",
            "Epoch 621/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 1.3350 - val_accuracy: 0.7720\n",
            "Epoch 622/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0884 - accuracy: 0.9704 - val_loss: 1.2668 - val_accuracy: 0.7710\n",
            "Epoch 623/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0925 - accuracy: 0.9654 - val_loss: 1.2998 - val_accuracy: 0.7650\n",
            "Epoch 624/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0924 - accuracy: 0.9673 - val_loss: 1.2942 - val_accuracy: 0.7590\n",
            "Epoch 625/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0962 - accuracy: 0.9657 - val_loss: 1.2798 - val_accuracy: 0.7560\n",
            "Epoch 626/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0836 - accuracy: 0.9706 - val_loss: 1.3056 - val_accuracy: 0.7680\n",
            "Epoch 627/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 1.3106 - val_accuracy: 0.7640\n",
            "Epoch 628/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0903 - accuracy: 0.9678 - val_loss: 1.3826 - val_accuracy: 0.7670\n",
            "Epoch 629/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0905 - accuracy: 0.9680 - val_loss: 1.3376 - val_accuracy: 0.7690\n",
            "Epoch 630/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0931 - accuracy: 0.9671 - val_loss: 1.2846 - val_accuracy: 0.7670\n",
            "Epoch 631/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 1.3259 - val_accuracy: 0.7690\n",
            "Epoch 632/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0890 - accuracy: 0.9687 - val_loss: 1.3276 - val_accuracy: 0.7760\n",
            "Epoch 633/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0876 - accuracy: 0.9685 - val_loss: 1.3117 - val_accuracy: 0.7750\n",
            "Epoch 634/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0907 - accuracy: 0.9695 - val_loss: 1.3681 - val_accuracy: 0.7740\n",
            "Epoch 635/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0877 - accuracy: 0.9708 - val_loss: 1.3372 - val_accuracy: 0.7660\n",
            "Epoch 636/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0895 - accuracy: 0.9690 - val_loss: 1.2684 - val_accuracy: 0.7570\n",
            "Epoch 637/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0913 - accuracy: 0.9676 - val_loss: 1.3052 - val_accuracy: 0.7650\n",
            "Epoch 638/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0871 - accuracy: 0.9704 - val_loss: 1.3582 - val_accuracy: 0.7670\n",
            "Epoch 639/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0832 - accuracy: 0.9706 - val_loss: 1.3648 - val_accuracy: 0.7670\n",
            "Epoch 640/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0869 - accuracy: 0.9707 - val_loss: 1.2938 - val_accuracy: 0.7710\n",
            "Epoch 641/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0927 - accuracy: 0.9680 - val_loss: 1.3081 - val_accuracy: 0.7640\n",
            "Epoch 642/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0906 - accuracy: 0.9666 - val_loss: 1.3528 - val_accuracy: 0.7640\n",
            "Epoch 643/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0910 - accuracy: 0.9685 - val_loss: 1.3027 - val_accuracy: 0.7760\n",
            "Epoch 644/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0797 - accuracy: 0.9717 - val_loss: 1.3289 - val_accuracy: 0.7820\n",
            "Epoch 645/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0911 - accuracy: 0.9687 - val_loss: 1.2905 - val_accuracy: 0.7620\n",
            "Epoch 646/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0922 - accuracy: 0.9683 - val_loss: 1.4245 - val_accuracy: 0.7700\n",
            "Epoch 647/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0875 - accuracy: 0.9677 - val_loss: 1.3319 - val_accuracy: 0.7680\n",
            "Epoch 648/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 1.3393 - val_accuracy: 0.7720\n",
            "Epoch 649/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0908 - accuracy: 0.9700 - val_loss: 1.4344 - val_accuracy: 0.7560\n",
            "Epoch 650/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0926 - accuracy: 0.9686 - val_loss: 1.2840 - val_accuracy: 0.7650\n",
            "Epoch 651/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0858 - accuracy: 0.9712 - val_loss: 1.3482 - val_accuracy: 0.7710\n",
            "Epoch 652/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0880 - accuracy: 0.9717 - val_loss: 1.4661 - val_accuracy: 0.7540\n",
            "Epoch 653/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0834 - accuracy: 0.9711 - val_loss: 1.3751 - val_accuracy: 0.7680\n",
            "Epoch 654/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0946 - accuracy: 0.9694 - val_loss: 1.3023 - val_accuracy: 0.7640\n",
            "Epoch 655/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0915 - accuracy: 0.9696 - val_loss: 1.2554 - val_accuracy: 0.7680\n",
            "Epoch 656/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0872 - accuracy: 0.9702 - val_loss: 1.4385 - val_accuracy: 0.7680\n",
            "Epoch 657/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0846 - accuracy: 0.9716 - val_loss: 1.3999 - val_accuracy: 0.7720\n",
            "Epoch 658/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0843 - accuracy: 0.9707 - val_loss: 1.3448 - val_accuracy: 0.7690\n",
            "Epoch 659/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0902 - accuracy: 0.9703 - val_loss: 1.3041 - val_accuracy: 0.7680\n",
            "Epoch 660/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0892 - accuracy: 0.9714 - val_loss: 1.3272 - val_accuracy: 0.7670\n",
            "Epoch 661/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0882 - accuracy: 0.9666 - val_loss: 1.2786 - val_accuracy: 0.7650\n",
            "Epoch 662/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0932 - accuracy: 0.9679 - val_loss: 1.3326 - val_accuracy: 0.7750\n",
            "Epoch 663/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0853 - accuracy: 0.9692 - val_loss: 1.3742 - val_accuracy: 0.7640\n",
            "Epoch 664/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0822 - accuracy: 0.9714 - val_loss: 1.3731 - val_accuracy: 0.7620\n",
            "Epoch 665/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0849 - accuracy: 0.9713 - val_loss: 1.3751 - val_accuracy: 0.7770\n",
            "Epoch 666/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 1.2789 - val_accuracy: 0.7730\n",
            "Epoch 667/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 1.3279 - val_accuracy: 0.7680\n",
            "Epoch 668/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0840 - accuracy: 0.9710 - val_loss: 1.2214 - val_accuracy: 0.7690\n",
            "Epoch 669/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0871 - accuracy: 0.9700 - val_loss: 1.4706 - val_accuracy: 0.7650\n",
            "Epoch 670/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0881 - accuracy: 0.9717 - val_loss: 1.4086 - val_accuracy: 0.7620\n",
            "Epoch 671/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0875 - accuracy: 0.9672 - val_loss: 1.3963 - val_accuracy: 0.7780\n",
            "Epoch 672/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 1.3202 - val_accuracy: 0.7590\n",
            "Epoch 673/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0933 - accuracy: 0.9677 - val_loss: 1.3395 - val_accuracy: 0.7670\n",
            "Epoch 674/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 1.3230 - val_accuracy: 0.7660\n",
            "Epoch 675/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0915 - accuracy: 0.9695 - val_loss: 1.3046 - val_accuracy: 0.7680\n",
            "Epoch 676/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0778 - accuracy: 0.9737 - val_loss: 1.3805 - val_accuracy: 0.7790\n",
            "Epoch 677/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 1.3362 - val_accuracy: 0.7720\n",
            "Epoch 678/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0870 - accuracy: 0.9705 - val_loss: 1.4034 - val_accuracy: 0.7700\n",
            "Epoch 679/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0903 - accuracy: 0.9691 - val_loss: 1.2942 - val_accuracy: 0.7620\n",
            "Epoch 680/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0855 - accuracy: 0.9728 - val_loss: 1.2763 - val_accuracy: 0.7700\n",
            "Epoch 681/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0860 - accuracy: 0.9705 - val_loss: 1.3331 - val_accuracy: 0.7760\n",
            "Epoch 682/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0849 - accuracy: 0.9723 - val_loss: 1.4563 - val_accuracy: 0.7650\n",
            "Epoch 683/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0814 - accuracy: 0.9712 - val_loss: 1.4322 - val_accuracy: 0.7690\n",
            "Epoch 684/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0791 - accuracy: 0.9728 - val_loss: 1.3855 - val_accuracy: 0.7710\n",
            "Epoch 685/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0807 - accuracy: 0.9723 - val_loss: 1.4022 - val_accuracy: 0.7710\n",
            "Epoch 686/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0897 - accuracy: 0.9698 - val_loss: 1.4104 - val_accuracy: 0.7670\n",
            "Epoch 687/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0898 - accuracy: 0.9677 - val_loss: 1.3050 - val_accuracy: 0.7720\n",
            "Epoch 688/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 1.4057 - val_accuracy: 0.7740\n",
            "Epoch 689/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0879 - accuracy: 0.9706 - val_loss: 1.3337 - val_accuracy: 0.7630\n",
            "Epoch 690/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0749 - accuracy: 0.9728 - val_loss: 1.4778 - val_accuracy: 0.7650\n",
            "Epoch 691/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0863 - accuracy: 0.9709 - val_loss: 1.3116 - val_accuracy: 0.7740\n",
            "Epoch 692/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0867 - accuracy: 0.9709 - val_loss: 1.3394 - val_accuracy: 0.7530\n",
            "Epoch 693/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0876 - accuracy: 0.9714 - val_loss: 1.4277 - val_accuracy: 0.7560\n",
            "Epoch 694/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0886 - accuracy: 0.9692 - val_loss: 1.4007 - val_accuracy: 0.7610\n",
            "Epoch 695/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0855 - accuracy: 0.9705 - val_loss: 1.3169 - val_accuracy: 0.7680\n",
            "Epoch 696/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.9738 - val_loss: 1.4499 - val_accuracy: 0.7730\n",
            "Epoch 697/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0789 - accuracy: 0.9718 - val_loss: 1.4515 - val_accuracy: 0.7660\n",
            "Epoch 698/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0939 - accuracy: 0.9700 - val_loss: 1.4428 - val_accuracy: 0.7570\n",
            "Epoch 699/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.9698 - val_loss: 1.4083 - val_accuracy: 0.7630\n",
            "Epoch 700/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0879 - accuracy: 0.9707 - val_loss: 1.3061 - val_accuracy: 0.7680\n",
            "Epoch 701/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 1.4034 - val_accuracy: 0.7720\n",
            "Epoch 702/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0854 - accuracy: 0.9698 - val_loss: 1.4739 - val_accuracy: 0.7640\n",
            "Epoch 703/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0871 - accuracy: 0.9702 - val_loss: 1.3974 - val_accuracy: 0.7600\n",
            "Epoch 704/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0849 - accuracy: 0.9703 - val_loss: 1.3746 - val_accuracy: 0.7760\n",
            "Epoch 705/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0847 - accuracy: 0.9700 - val_loss: 1.4626 - val_accuracy: 0.7630\n",
            "Epoch 706/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 1.3822 - val_accuracy: 0.7660\n",
            "Epoch 707/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0887 - accuracy: 0.9703 - val_loss: 1.3943 - val_accuracy: 0.7660\n",
            "Epoch 708/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 1.3210 - val_accuracy: 0.7660\n",
            "Epoch 709/1000\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0791 - accuracy: 0.9724 - val_loss: 1.3709 - val_accuracy: 0.7650\n",
            "Epoch 710/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0839 - accuracy: 0.9729 - val_loss: 1.3552 - val_accuracy: 0.7660\n",
            "Epoch 711/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 1.3510 - val_accuracy: 0.7640\n",
            "Epoch 712/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0877 - accuracy: 0.9713 - val_loss: 1.3462 - val_accuracy: 0.7640\n",
            "Epoch 713/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0889 - accuracy: 0.9682 - val_loss: 1.3883 - val_accuracy: 0.7550\n",
            "Epoch 714/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0856 - accuracy: 0.9708 - val_loss: 1.4267 - val_accuracy: 0.7610\n",
            "Epoch 715/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0865 - accuracy: 0.9717 - val_loss: 1.3575 - val_accuracy: 0.7730\n",
            "Epoch 716/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0844 - accuracy: 0.9710 - val_loss: 1.3769 - val_accuracy: 0.7630\n",
            "Epoch 717/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0822 - accuracy: 0.9706 - val_loss: 1.3768 - val_accuracy: 0.7650\n",
            "Epoch 718/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 1.4623 - val_accuracy: 0.7670\n",
            "Epoch 719/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0840 - accuracy: 0.9700 - val_loss: 1.4448 - val_accuracy: 0.7620\n",
            "Epoch 720/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0844 - accuracy: 0.9733 - val_loss: 1.4570 - val_accuracy: 0.7710\n",
            "Epoch 721/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0815 - accuracy: 0.9719 - val_loss: 1.3854 - val_accuracy: 0.7650\n",
            "Epoch 722/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0898 - accuracy: 0.9696 - val_loss: 1.2997 - val_accuracy: 0.7680\n",
            "Epoch 723/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0863 - accuracy: 0.9689 - val_loss: 1.4366 - val_accuracy: 0.7630\n",
            "Epoch 724/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0775 - accuracy: 0.9736 - val_loss: 1.4121 - val_accuracy: 0.7690\n",
            "Epoch 725/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0755 - accuracy: 0.9731 - val_loss: 1.3876 - val_accuracy: 0.7610\n",
            "Epoch 726/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0847 - accuracy: 0.9722 - val_loss: 1.3369 - val_accuracy: 0.7680\n",
            "Epoch 727/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0850 - accuracy: 0.9696 - val_loss: 1.4093 - val_accuracy: 0.7660\n",
            "Epoch 728/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0789 - accuracy: 0.9719 - val_loss: 1.4725 - val_accuracy: 0.7630\n",
            "Epoch 729/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 1.5634 - val_accuracy: 0.7640\n",
            "Epoch 730/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0862 - accuracy: 0.9703 - val_loss: 1.4317 - val_accuracy: 0.7660\n",
            "Epoch 731/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0773 - accuracy: 0.9741 - val_loss: 1.4718 - val_accuracy: 0.7640\n",
            "Epoch 732/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 1.5019 - val_accuracy: 0.7680\n",
            "Epoch 733/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0825 - accuracy: 0.9707 - val_loss: 1.3858 - val_accuracy: 0.7680\n",
            "Epoch 734/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0841 - accuracy: 0.9726 - val_loss: 1.4213 - val_accuracy: 0.7490\n",
            "Epoch 735/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 1.3960 - val_accuracy: 0.7680\n",
            "Epoch 736/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0885 - accuracy: 0.9687 - val_loss: 1.4571 - val_accuracy: 0.7630\n",
            "Epoch 737/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0820 - accuracy: 0.9715 - val_loss: 1.5045 - val_accuracy: 0.7530\n",
            "Epoch 738/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9742 - val_loss: 1.5761 - val_accuracy: 0.7430\n",
            "Epoch 739/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0817 - accuracy: 0.9720 - val_loss: 1.4509 - val_accuracy: 0.7580\n",
            "Epoch 740/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0816 - accuracy: 0.9722 - val_loss: 1.3718 - val_accuracy: 0.7710\n",
            "Epoch 741/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0853 - accuracy: 0.9703 - val_loss: 1.3055 - val_accuracy: 0.7670\n",
            "Epoch 742/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0759 - accuracy: 0.9739 - val_loss: 1.4513 - val_accuracy: 0.7610\n",
            "Epoch 743/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0843 - accuracy: 0.9719 - val_loss: 1.3963 - val_accuracy: 0.7680\n",
            "Epoch 744/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 1.4210 - val_accuracy: 0.7620\n",
            "Epoch 745/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0764 - accuracy: 0.9727 - val_loss: 1.5923 - val_accuracy: 0.7620\n",
            "Epoch 746/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0887 - accuracy: 0.9708 - val_loss: 1.3926 - val_accuracy: 0.7640\n",
            "Epoch 747/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0832 - accuracy: 0.9725 - val_loss: 1.4364 - val_accuracy: 0.7740\n",
            "Epoch 748/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0848 - accuracy: 0.9722 - val_loss: 1.4249 - val_accuracy: 0.7600\n",
            "Epoch 749/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0764 - accuracy: 0.9747 - val_loss: 1.4443 - val_accuracy: 0.7610\n",
            "Epoch 750/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0797 - accuracy: 0.9722 - val_loss: 1.3388 - val_accuracy: 0.7710\n",
            "Epoch 751/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0847 - accuracy: 0.9701 - val_loss: 1.5085 - val_accuracy: 0.7680\n",
            "Epoch 752/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0783 - accuracy: 0.9754 - val_loss: 1.4321 - val_accuracy: 0.7700\n",
            "Epoch 753/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0906 - accuracy: 0.9687 - val_loss: 1.4382 - val_accuracy: 0.7580\n",
            "Epoch 754/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0731 - accuracy: 0.9741 - val_loss: 1.4038 - val_accuracy: 0.7630\n",
            "Epoch 755/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0918 - accuracy: 0.9715 - val_loss: 1.3883 - val_accuracy: 0.7590\n",
            "Epoch 756/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0816 - accuracy: 0.9734 - val_loss: 1.4513 - val_accuracy: 0.7720\n",
            "Epoch 757/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0849 - accuracy: 0.9692 - val_loss: 1.3178 - val_accuracy: 0.7610\n",
            "Epoch 758/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 1.4501 - val_accuracy: 0.7600\n",
            "Epoch 759/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0740 - accuracy: 0.9723 - val_loss: 1.4650 - val_accuracy: 0.7590\n",
            "Epoch 760/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 1.4951 - val_accuracy: 0.7710\n",
            "Epoch 761/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0814 - accuracy: 0.9715 - val_loss: 1.4574 - val_accuracy: 0.7560\n",
            "Epoch 762/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0834 - accuracy: 0.9708 - val_loss: 1.3969 - val_accuracy: 0.7620\n",
            "Epoch 763/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0861 - accuracy: 0.9710 - val_loss: 1.3737 - val_accuracy: 0.7730\n",
            "Epoch 764/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0837 - accuracy: 0.9723 - val_loss: 1.3398 - val_accuracy: 0.7650\n",
            "Epoch 765/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0809 - accuracy: 0.9729 - val_loss: 1.3414 - val_accuracy: 0.7800\n",
            "Epoch 766/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0854 - accuracy: 0.9716 - val_loss: 1.3549 - val_accuracy: 0.7690\n",
            "Epoch 767/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0780 - accuracy: 0.9740 - val_loss: 1.3734 - val_accuracy: 0.7660\n",
            "Epoch 768/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0798 - accuracy: 0.9725 - val_loss: 1.3943 - val_accuracy: 0.7720\n",
            "Epoch 769/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0847 - accuracy: 0.9700 - val_loss: 1.2471 - val_accuracy: 0.7730\n",
            "Epoch 770/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0876 - accuracy: 0.9725 - val_loss: 1.3882 - val_accuracy: 0.7720\n",
            "Epoch 771/1000\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0851 - accuracy: 0.9733 - val_loss: 1.2741 - val_accuracy: 0.7660\n",
            "Epoch 772/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0799 - accuracy: 0.9721 - val_loss: 1.3754 - val_accuracy: 0.7810\n",
            "Epoch 773/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0812 - accuracy: 0.9733 - val_loss: 1.3613 - val_accuracy: 0.7710\n",
            "Epoch 774/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0835 - accuracy: 0.9721 - val_loss: 1.4698 - val_accuracy: 0.7570\n",
            "Epoch 775/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0874 - accuracy: 0.9727 - val_loss: 1.2825 - val_accuracy: 0.7670\n",
            "Epoch 776/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 1.4420 - val_accuracy: 0.7660\n",
            "Epoch 777/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0849 - accuracy: 0.9738 - val_loss: 1.4331 - val_accuracy: 0.7700\n",
            "Epoch 778/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 1.3802 - val_accuracy: 0.7770\n",
            "Epoch 779/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0815 - accuracy: 0.9733 - val_loss: 1.3412 - val_accuracy: 0.7670\n",
            "Epoch 780/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0760 - accuracy: 0.9738 - val_loss: 1.4007 - val_accuracy: 0.7750\n",
            "Epoch 781/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 1.5070 - val_accuracy: 0.7780\n",
            "Epoch 782/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0708 - accuracy: 0.9752 - val_loss: 1.5752 - val_accuracy: 0.7690\n",
            "Epoch 783/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0841 - accuracy: 0.9709 - val_loss: 1.3613 - val_accuracy: 0.7660\n",
            "Epoch 784/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0861 - accuracy: 0.9716 - val_loss: 1.3521 - val_accuracy: 0.7600\n",
            "Epoch 785/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 1.3599 - val_accuracy: 0.7680\n",
            "Epoch 786/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0729 - accuracy: 0.9741 - val_loss: 1.5058 - val_accuracy: 0.7540\n",
            "Epoch 787/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0818 - accuracy: 0.9725 - val_loss: 1.4938 - val_accuracy: 0.7660\n",
            "Epoch 788/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9755 - val_loss: 1.5933 - val_accuracy: 0.7730\n",
            "Epoch 789/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0758 - accuracy: 0.9735 - val_loss: 1.4253 - val_accuracy: 0.7560\n",
            "Epoch 790/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0838 - accuracy: 0.9711 - val_loss: 1.3711 - val_accuracy: 0.7670\n",
            "Epoch 791/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0796 - accuracy: 0.9760 - val_loss: 1.4172 - val_accuracy: 0.7660\n",
            "Epoch 792/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0735 - accuracy: 0.9745 - val_loss: 1.5422 - val_accuracy: 0.7610\n",
            "Epoch 793/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0814 - accuracy: 0.9739 - val_loss: 1.5738 - val_accuracy: 0.7720\n",
            "Epoch 794/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0776 - accuracy: 0.9749 - val_loss: 1.4611 - val_accuracy: 0.7660\n",
            "Epoch 795/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0822 - accuracy: 0.9731 - val_loss: 1.3958 - val_accuracy: 0.7600\n",
            "Epoch 796/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0864 - accuracy: 0.9719 - val_loss: 1.4776 - val_accuracy: 0.7570\n",
            "Epoch 797/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0760 - accuracy: 0.9741 - val_loss: 1.5635 - val_accuracy: 0.7720\n",
            "Epoch 798/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0772 - accuracy: 0.9749 - val_loss: 1.4279 - val_accuracy: 0.7660\n",
            "Epoch 799/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0761 - accuracy: 0.9725 - val_loss: 1.4870 - val_accuracy: 0.7540\n",
            "Epoch 800/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0776 - accuracy: 0.9740 - val_loss: 1.5674 - val_accuracy: 0.7660\n",
            "Epoch 801/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0798 - accuracy: 0.9728 - val_loss: 1.4823 - val_accuracy: 0.7610\n",
            "Epoch 802/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0802 - accuracy: 0.9745 - val_loss: 1.4198 - val_accuracy: 0.7560\n",
            "Epoch 803/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 1.3947 - val_accuracy: 0.7610\n",
            "Epoch 804/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0766 - accuracy: 0.9732 - val_loss: 1.3793 - val_accuracy: 0.7640\n",
            "Epoch 805/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0764 - accuracy: 0.9746 - val_loss: 1.4027 - val_accuracy: 0.7590\n",
            "Epoch 806/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0834 - accuracy: 0.9727 - val_loss: 1.4116 - val_accuracy: 0.7680\n",
            "Epoch 807/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 1.3237 - val_accuracy: 0.7680\n",
            "Epoch 808/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0757 - accuracy: 0.9754 - val_loss: 1.4016 - val_accuracy: 0.7640\n",
            "Epoch 809/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0765 - accuracy: 0.9748 - val_loss: 1.4254 - val_accuracy: 0.7590\n",
            "Epoch 810/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0785 - accuracy: 0.9722 - val_loss: 1.4030 - val_accuracy: 0.7650\n",
            "Epoch 811/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 1.4716 - val_accuracy: 0.7560\n",
            "Epoch 812/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0728 - accuracy: 0.9753 - val_loss: 1.4565 - val_accuracy: 0.7550\n",
            "Epoch 813/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0778 - accuracy: 0.9730 - val_loss: 1.5469 - val_accuracy: 0.7530\n",
            "Epoch 814/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0810 - accuracy: 0.9747 - val_loss: 1.4051 - val_accuracy: 0.7600\n",
            "Epoch 815/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0736 - accuracy: 0.9753 - val_loss: 1.5012 - val_accuracy: 0.7510\n",
            "Epoch 816/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0861 - accuracy: 0.9722 - val_loss: 1.4444 - val_accuracy: 0.7610\n",
            "Epoch 817/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0772 - accuracy: 0.9739 - val_loss: 1.4268 - val_accuracy: 0.7640\n",
            "Epoch 818/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0776 - accuracy: 0.9725 - val_loss: 1.3814 - val_accuracy: 0.7600\n",
            "Epoch 819/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 1.4826 - val_accuracy: 0.7550\n",
            "Epoch 820/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 1.4250 - val_accuracy: 0.7620\n",
            "Epoch 821/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0692 - accuracy: 0.9753 - val_loss: 1.5199 - val_accuracy: 0.7680\n",
            "Epoch 822/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0831 - accuracy: 0.9711 - val_loss: 1.4188 - val_accuracy: 0.7540\n",
            "Epoch 823/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0755 - accuracy: 0.9735 - val_loss: 1.3977 - val_accuracy: 0.7840\n",
            "Epoch 824/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0815 - accuracy: 0.9735 - val_loss: 1.3977 - val_accuracy: 0.7680\n",
            "Epoch 825/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0792 - accuracy: 0.9730 - val_loss: 1.5294 - val_accuracy: 0.7690\n",
            "Epoch 826/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0736 - accuracy: 0.9744 - val_loss: 1.4402 - val_accuracy: 0.7530\n",
            "Epoch 827/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.9749 - val_loss: 1.4721 - val_accuracy: 0.7650\n",
            "Epoch 828/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0798 - accuracy: 0.9735 - val_loss: 1.5347 - val_accuracy: 0.7500\n",
            "Epoch 829/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0715 - accuracy: 0.9760 - val_loss: 1.4402 - val_accuracy: 0.7610\n",
            "Epoch 830/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0807 - accuracy: 0.9740 - val_loss: 1.3783 - val_accuracy: 0.7630\n",
            "Epoch 831/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0753 - accuracy: 0.9743 - val_loss: 1.4384 - val_accuracy: 0.7580\n",
            "Epoch 832/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0745 - accuracy: 0.9738 - val_loss: 1.5269 - val_accuracy: 0.7550\n",
            "Epoch 833/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0777 - accuracy: 0.9748 - val_loss: 1.3483 - val_accuracy: 0.7660\n",
            "Epoch 834/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0783 - accuracy: 0.9735 - val_loss: 1.4552 - val_accuracy: 0.7640\n",
            "Epoch 835/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0768 - accuracy: 0.9738 - val_loss: 1.3799 - val_accuracy: 0.7570\n",
            "Epoch 836/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 1.4250 - val_accuracy: 0.7730\n",
            "Epoch 837/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0766 - accuracy: 0.9747 - val_loss: 1.4613 - val_accuracy: 0.7650\n",
            "Epoch 838/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0774 - accuracy: 0.9731 - val_loss: 1.3896 - val_accuracy: 0.7590\n",
            "Epoch 839/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 1.3965 - val_accuracy: 0.7690\n",
            "Epoch 840/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0711 - accuracy: 0.9773 - val_loss: 1.3641 - val_accuracy: 0.7720\n",
            "Epoch 841/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0778 - accuracy: 0.9739 - val_loss: 1.4728 - val_accuracy: 0.7660\n",
            "Epoch 842/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0763 - accuracy: 0.9747 - val_loss: 1.3677 - val_accuracy: 0.7760\n",
            "Epoch 843/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 1.4140 - val_accuracy: 0.7620\n",
            "Epoch 844/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0803 - accuracy: 0.9738 - val_loss: 1.3100 - val_accuracy: 0.7590\n",
            "Epoch 845/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0715 - accuracy: 0.9740 - val_loss: 1.4806 - val_accuracy: 0.7550\n",
            "Epoch 846/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0734 - accuracy: 0.9736 - val_loss: 1.4417 - val_accuracy: 0.7700\n",
            "Epoch 847/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: 1.4628 - val_accuracy: 0.7620\n",
            "Epoch 848/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0832 - accuracy: 0.9724 - val_loss: 1.4609 - val_accuracy: 0.7670\n",
            "Epoch 849/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0701 - accuracy: 0.9757 - val_loss: 1.3906 - val_accuracy: 0.7670\n",
            "Epoch 850/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0740 - accuracy: 0.9743 - val_loss: 1.3341 - val_accuracy: 0.7620\n",
            "Epoch 851/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.9730 - val_loss: 1.3982 - val_accuracy: 0.7720\n",
            "Epoch 852/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 1.4267 - val_accuracy: 0.7660\n",
            "Epoch 853/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0748 - accuracy: 0.9740 - val_loss: 1.4496 - val_accuracy: 0.7680\n",
            "Epoch 854/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0713 - accuracy: 0.9745 - val_loss: 1.5174 - val_accuracy: 0.7540\n",
            "Epoch 855/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0749 - accuracy: 0.9757 - val_loss: 1.3798 - val_accuracy: 0.7730\n",
            "Epoch 856/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 1.3779 - val_accuracy: 0.7690\n",
            "Epoch 857/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0821 - accuracy: 0.9730 - val_loss: 1.4123 - val_accuracy: 0.7650\n",
            "Epoch 858/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0829 - accuracy: 0.9737 - val_loss: 1.3608 - val_accuracy: 0.7620\n",
            "Epoch 859/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0744 - accuracy: 0.9747 - val_loss: 1.5016 - val_accuracy: 0.7660\n",
            "Epoch 860/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0772 - accuracy: 0.9742 - val_loss: 1.4746 - val_accuracy: 0.7660\n",
            "Epoch 861/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0783 - accuracy: 0.9739 - val_loss: 1.4482 - val_accuracy: 0.7580\n",
            "Epoch 862/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 1.5369 - val_accuracy: 0.7570\n",
            "Epoch 863/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 1.5459 - val_accuracy: 0.7620\n",
            "Epoch 864/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0870 - accuracy: 0.9732 - val_loss: 1.4422 - val_accuracy: 0.7570\n",
            "Epoch 865/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 1.5144 - val_accuracy: 0.7600\n",
            "Epoch 866/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0769 - accuracy: 0.9764 - val_loss: 1.4848 - val_accuracy: 0.7590\n",
            "Epoch 867/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 1.3826 - val_accuracy: 0.7630\n",
            "Epoch 868/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0717 - accuracy: 0.9763 - val_loss: 1.5477 - val_accuracy: 0.7650\n",
            "Epoch 869/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9756 - val_loss: 1.4946 - val_accuracy: 0.7630\n",
            "Epoch 870/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0788 - accuracy: 0.9739 - val_loss: 1.4719 - val_accuracy: 0.7670\n",
            "Epoch 871/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0690 - accuracy: 0.9757 - val_loss: 1.4871 - val_accuracy: 0.7460\n",
            "Epoch 872/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0696 - accuracy: 0.9765 - val_loss: 1.5288 - val_accuracy: 0.7500\n",
            "Epoch 873/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 1.5356 - val_accuracy: 0.7510\n",
            "Epoch 874/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0735 - accuracy: 0.9765 - val_loss: 1.5530 - val_accuracy: 0.7670\n",
            "Epoch 875/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0724 - accuracy: 0.9755 - val_loss: 1.5002 - val_accuracy: 0.7690\n",
            "Epoch 876/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0814 - accuracy: 0.9737 - val_loss: 1.5203 - val_accuracy: 0.7640\n",
            "Epoch 877/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0776 - accuracy: 0.9743 - val_loss: 1.4978 - val_accuracy: 0.7520\n",
            "Epoch 878/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0727 - accuracy: 0.9783 - val_loss: 1.5221 - val_accuracy: 0.7500\n",
            "Epoch 879/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9742 - val_loss: 1.5628 - val_accuracy: 0.7610\n",
            "Epoch 880/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0851 - accuracy: 0.9735 - val_loss: 1.5683 - val_accuracy: 0.7510\n",
            "Epoch 881/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0762 - accuracy: 0.9769 - val_loss: 1.5225 - val_accuracy: 0.7540\n",
            "Epoch 882/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0717 - accuracy: 0.9758 - val_loss: 1.4341 - val_accuracy: 0.7630\n",
            "Epoch 883/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 1.3601 - val_accuracy: 0.7610\n",
            "Epoch 884/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0741 - accuracy: 0.9739 - val_loss: 1.4881 - val_accuracy: 0.7610\n",
            "Epoch 885/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0753 - accuracy: 0.9756 - val_loss: 1.4606 - val_accuracy: 0.7550\n",
            "Epoch 886/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0755 - accuracy: 0.9759 - val_loss: 1.4732 - val_accuracy: 0.7530\n",
            "Epoch 887/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0766 - accuracy: 0.9757 - val_loss: 1.4984 - val_accuracy: 0.7580\n",
            "Epoch 888/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0747 - accuracy: 0.9763 - val_loss: 1.6239 - val_accuracy: 0.7610\n",
            "Epoch 889/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0722 - accuracy: 0.9757 - val_loss: 1.4181 - val_accuracy: 0.7560\n",
            "Epoch 890/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0783 - accuracy: 0.9740 - val_loss: 1.4954 - val_accuracy: 0.7620\n",
            "Epoch 891/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0745 - accuracy: 0.9745 - val_loss: 1.4748 - val_accuracy: 0.7630\n",
            "Epoch 892/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0741 - accuracy: 0.9749 - val_loss: 1.4093 - val_accuracy: 0.7650\n",
            "Epoch 893/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0744 - accuracy: 0.9756 - val_loss: 1.4359 - val_accuracy: 0.7590\n",
            "Epoch 894/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0745 - accuracy: 0.9741 - val_loss: 1.4917 - val_accuracy: 0.7720\n",
            "Epoch 895/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0690 - accuracy: 0.9767 - val_loss: 1.5287 - val_accuracy: 0.7570\n",
            "Epoch 896/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 1.4616 - val_accuracy: 0.7580\n",
            "Epoch 897/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0738 - accuracy: 0.9778 - val_loss: 1.5949 - val_accuracy: 0.7640\n",
            "Epoch 898/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0764 - accuracy: 0.9759 - val_loss: 1.4952 - val_accuracy: 0.7730\n",
            "Epoch 899/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0729 - accuracy: 0.9759 - val_loss: 1.4727 - val_accuracy: 0.7640\n",
            "Epoch 900/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 1.6952 - val_accuracy: 0.7600\n",
            "Epoch 901/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0781 - accuracy: 0.9716 - val_loss: 1.5787 - val_accuracy: 0.7690\n",
            "Epoch 902/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0683 - accuracy: 0.9795 - val_loss: 1.4789 - val_accuracy: 0.7710\n",
            "Epoch 903/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 1.5077 - val_accuracy: 0.7660\n",
            "Epoch 904/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0705 - accuracy: 0.9779 - val_loss: 1.5462 - val_accuracy: 0.7520\n",
            "Epoch 905/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 1.4409 - val_accuracy: 0.7620\n",
            "Epoch 906/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 1.4917 - val_accuracy: 0.7720\n",
            "Epoch 907/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0792 - accuracy: 0.9727 - val_loss: 1.4491 - val_accuracy: 0.7660\n",
            "Epoch 908/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 1.5508 - val_accuracy: 0.7560\n",
            "Epoch 909/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0773 - accuracy: 0.9759 - val_loss: 1.5059 - val_accuracy: 0.7680\n",
            "Epoch 910/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 1.5836 - val_accuracy: 0.7680\n",
            "Epoch 911/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0778 - accuracy: 0.9764 - val_loss: 1.4433 - val_accuracy: 0.7760\n",
            "Epoch 912/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0723 - accuracy: 0.9752 - val_loss: 1.4392 - val_accuracy: 0.7630\n",
            "Epoch 913/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0747 - accuracy: 0.9755 - val_loss: 1.4821 - val_accuracy: 0.7660\n",
            "Epoch 914/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 1.5582 - val_accuracy: 0.7750\n",
            "Epoch 915/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 1.5504 - val_accuracy: 0.7590\n",
            "Epoch 916/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0774 - accuracy: 0.9735 - val_loss: 1.5630 - val_accuracy: 0.7640\n",
            "Epoch 917/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0749 - accuracy: 0.9741 - val_loss: 1.5537 - val_accuracy: 0.7570\n",
            "Epoch 918/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0719 - accuracy: 0.9754 - val_loss: 1.5770 - val_accuracy: 0.7620\n",
            "Epoch 919/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0713 - accuracy: 0.9777 - val_loss: 1.5550 - val_accuracy: 0.7670\n",
            "Epoch 920/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.9755 - val_loss: 1.3884 - val_accuracy: 0.7630\n",
            "Epoch 921/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0729 - accuracy: 0.9752 - val_loss: 1.5041 - val_accuracy: 0.7710\n",
            "Epoch 922/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0732 - accuracy: 0.9756 - val_loss: 1.4404 - val_accuracy: 0.7700\n",
            "Epoch 923/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0772 - accuracy: 0.9740 - val_loss: 1.5763 - val_accuracy: 0.7690\n",
            "Epoch 924/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 1.4415 - val_accuracy: 0.7570\n",
            "Epoch 925/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0717 - accuracy: 0.9753 - val_loss: 1.5119 - val_accuracy: 0.7610\n",
            "Epoch 926/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0694 - accuracy: 0.9758 - val_loss: 1.4544 - val_accuracy: 0.7670\n",
            "Epoch 927/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 1.4330 - val_accuracy: 0.7620\n",
            "Epoch 928/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0687 - accuracy: 0.9770 - val_loss: 1.4221 - val_accuracy: 0.7630\n",
            "Epoch 929/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0747 - accuracy: 0.9759 - val_loss: 1.4136 - val_accuracy: 0.7670\n",
            "Epoch 930/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0825 - accuracy: 0.9745 - val_loss: 1.3621 - val_accuracy: 0.7680\n",
            "Epoch 931/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 1.5725 - val_accuracy: 0.7710\n",
            "Epoch 932/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 1.4557 - val_accuracy: 0.7680\n",
            "Epoch 933/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 1.6222 - val_accuracy: 0.7710\n",
            "Epoch 934/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0715 - accuracy: 0.9775 - val_loss: 1.6911 - val_accuracy: 0.7690\n",
            "Epoch 935/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0708 - accuracy: 0.9763 - val_loss: 1.5213 - val_accuracy: 0.7560\n",
            "Epoch 936/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0708 - accuracy: 0.9761 - val_loss: 1.4621 - val_accuracy: 0.7700\n",
            "Epoch 937/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 1.6490 - val_accuracy: 0.7640\n",
            "Epoch 938/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0774 - accuracy: 0.9756 - val_loss: 1.5260 - val_accuracy: 0.7680\n",
            "Epoch 939/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 1.5337 - val_accuracy: 0.7670\n",
            "Epoch 940/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 1.5011 - val_accuracy: 0.7670\n",
            "Epoch 941/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0801 - accuracy: 0.9725 - val_loss: 1.4938 - val_accuracy: 0.7700\n",
            "Epoch 942/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 1.4963 - val_accuracy: 0.7610\n",
            "Epoch 943/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0715 - accuracy: 0.9764 - val_loss: 1.4065 - val_accuracy: 0.7730\n",
            "Epoch 944/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9753 - val_loss: 1.5039 - val_accuracy: 0.7720\n",
            "Epoch 945/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0726 - accuracy: 0.9759 - val_loss: 1.5533 - val_accuracy: 0.7680\n",
            "Epoch 946/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0776 - accuracy: 0.9753 - val_loss: 1.5142 - val_accuracy: 0.7660\n",
            "Epoch 947/1000\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0724 - accuracy: 0.9764 - val_loss: 1.5340 - val_accuracy: 0.7640\n",
            "Epoch 948/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 1.3954 - val_accuracy: 0.7640\n",
            "Epoch 949/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0677 - accuracy: 0.9775 - val_loss: 1.4876 - val_accuracy: 0.7670\n",
            "Epoch 950/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 1.6752 - val_accuracy: 0.7540\n",
            "Epoch 951/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 1.5570 - val_accuracy: 0.7680\n",
            "Epoch 952/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 1.4800 - val_accuracy: 0.7730\n",
            "Epoch 953/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 1.4094 - val_accuracy: 0.7720\n",
            "Epoch 954/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 1.6607 - val_accuracy: 0.7670\n",
            "Epoch 955/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9776 - val_loss: 1.5410 - val_accuracy: 0.7700\n",
            "Epoch 956/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0726 - accuracy: 0.9749 - val_loss: 1.5306 - val_accuracy: 0.7820\n",
            "Epoch 957/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0729 - accuracy: 0.9763 - val_loss: 1.4887 - val_accuracy: 0.7680\n",
            "Epoch 958/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0756 - accuracy: 0.9757 - val_loss: 1.3507 - val_accuracy: 0.7720\n",
            "Epoch 959/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0657 - accuracy: 0.9787 - val_loss: 1.4858 - val_accuracy: 0.7690\n",
            "Epoch 960/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0743 - accuracy: 0.9768 - val_loss: 1.5891 - val_accuracy: 0.7540\n",
            "Epoch 961/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0691 - accuracy: 0.9765 - val_loss: 1.5680 - val_accuracy: 0.7590\n",
            "Epoch 962/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 1.5227 - val_accuracy: 0.7650\n",
            "Epoch 963/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0705 - accuracy: 0.9767 - val_loss: 1.5223 - val_accuracy: 0.7640\n",
            "Epoch 964/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9763 - val_loss: 1.5658 - val_accuracy: 0.7750\n",
            "Epoch 965/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0767 - accuracy: 0.9754 - val_loss: 1.4726 - val_accuracy: 0.7700\n",
            "Epoch 966/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0732 - accuracy: 0.9742 - val_loss: 1.4745 - val_accuracy: 0.7600\n",
            "Epoch 967/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0728 - accuracy: 0.9748 - val_loss: 1.5063 - val_accuracy: 0.7620\n",
            "Epoch 968/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 1.6028 - val_accuracy: 0.7700\n",
            "Epoch 969/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0705 - accuracy: 0.9748 - val_loss: 1.4886 - val_accuracy: 0.7660\n",
            "Epoch 970/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0722 - accuracy: 0.9751 - val_loss: 1.5141 - val_accuracy: 0.7640\n",
            "Epoch 971/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 1.5488 - val_accuracy: 0.7650\n",
            "Epoch 972/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0759 - accuracy: 0.9773 - val_loss: 1.5617 - val_accuracy: 0.7620\n",
            "Epoch 973/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0654 - accuracy: 0.9788 - val_loss: 1.5821 - val_accuracy: 0.7640\n",
            "Epoch 974/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 1.4836 - val_accuracy: 0.7660\n",
            "Epoch 975/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0680 - accuracy: 0.9771 - val_loss: 1.6533 - val_accuracy: 0.7640\n",
            "Epoch 976/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0765 - accuracy: 0.9748 - val_loss: 1.4779 - val_accuracy: 0.7720\n",
            "Epoch 977/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0720 - accuracy: 0.9768 - val_loss: 1.5347 - val_accuracy: 0.7670\n",
            "Epoch 978/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0746 - accuracy: 0.9764 - val_loss: 1.5130 - val_accuracy: 0.7670\n",
            "Epoch 979/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0696 - accuracy: 0.9765 - val_loss: 1.5639 - val_accuracy: 0.7540\n",
            "Epoch 980/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0712 - accuracy: 0.9771 - val_loss: 1.5543 - val_accuracy: 0.7690\n",
            "Epoch 981/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9748 - val_loss: 1.5818 - val_accuracy: 0.7690\n",
            "Epoch 982/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0800 - accuracy: 0.9731 - val_loss: 1.5812 - val_accuracy: 0.7660\n",
            "Epoch 983/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0771 - accuracy: 0.9779 - val_loss: 1.4653 - val_accuracy: 0.7610\n",
            "Epoch 984/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0687 - accuracy: 0.9773 - val_loss: 1.5307 - val_accuracy: 0.7610\n",
            "Epoch 985/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0670 - accuracy: 0.9774 - val_loss: 1.6189 - val_accuracy: 0.7580\n",
            "Epoch 986/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0673 - accuracy: 0.9781 - val_loss: 1.4736 - val_accuracy: 0.7580\n",
            "Epoch 987/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 1.5605 - val_accuracy: 0.7560\n",
            "Epoch 988/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0744 - accuracy: 0.9775 - val_loss: 1.5210 - val_accuracy: 0.7640\n",
            "Epoch 989/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0728 - accuracy: 0.9778 - val_loss: 1.5808 - val_accuracy: 0.7640\n",
            "Epoch 990/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0738 - accuracy: 0.9765 - val_loss: 1.5354 - val_accuracy: 0.7590\n",
            "Epoch 991/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 1.5213 - val_accuracy: 0.7670\n",
            "Epoch 992/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0733 - accuracy: 0.9754 - val_loss: 1.5533 - val_accuracy: 0.7680\n",
            "Epoch 993/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0642 - accuracy: 0.9783 - val_loss: 1.7073 - val_accuracy: 0.7630\n",
            "Epoch 994/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 1.4763 - val_accuracy: 0.7670\n",
            "Epoch 995/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 1.5274 - val_accuracy: 0.7740\n",
            "Epoch 996/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0746 - accuracy: 0.9769 - val_loss: 1.5211 - val_accuracy: 0.7620\n",
            "Epoch 997/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 1.4413 - val_accuracy: 0.7690\n",
            "Epoch 998/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0710 - accuracy: 0.9747 - val_loss: 1.5544 - val_accuracy: 0.7640\n",
            "Epoch 999/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0764 - accuracy: 0.9747 - val_loss: 1.4949 - val_accuracy: 0.7610\n",
            "Epoch 1000/1000\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0776 - accuracy: 0.9757 - val_loss: 1.4119 - val_accuracy: 0.7700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjVDs-oxEKnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79a6f20-7777-460b-ae66-f21f606954b7"
      },
      "source": [
        "filename = 'Z_chatbot_100_epochs.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyu-r57GEKnd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "a01fe4a3-00fc-4329-edab-7c0dd9a9c6a0"
      },
      "source": [
        "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
        "#We can see that without any training the acc is about 50%, random guessing\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4anqyxegEKnd"
      },
      "source": [
        "#To load a model that we have already trained and saved:\n",
        "model.load_weights('Z_chatbot_100_epochs.h5')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygUIuEG8EKne"
      },
      "source": [
        "#Lets check out the predictions on the test set:\n",
        "#These are just probabilities for every single word on the vocab\n",
        "pred_results = model.predict(([inputs_test,questions_test]))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jbxNhryEKne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fc79c8-7bf9-4603-8142-825724d964dc"
      },
      "source": [
        "#First test data point\n",
        "test_data[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'got',\n",
              "  'the',\n",
              "  'milk',\n",
              "  'there',\n",
              "  '.',\n",
              "  'John',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRuelEsWEKne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8580279-c21e-4fe2-ec3b-64cf3442f526"
      },
      "source": [
        "#These are the probabilities for the vocab words using the 1st sentence\n",
        "pred_results[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.16537214e-11, 1.18046163e-11, 1.20038970e-11, 1.24342923e-11,\n",
              "       1.22016329e-11, 1.21972822e-11, 1.19901901e-11, 1.20626313e-11,\n",
              "       1.21810999e-11, 1.28157927e-11, 1.21490569e-11, 1.14600569e-11,\n",
              "       1.17032391e-11, 1.17085291e-11, 1.12691583e-11, 1.09737905e-11,\n",
              "       1.25374823e-11, 1.24265398e-11, 1.24256395e-11, 1.99930539e-04,\n",
              "       1.17505684e-11, 1.17144940e-11, 1.14592034e-11, 1.13558963e-11,\n",
              "       1.24659710e-11, 1.18636186e-11, 1.21140927e-11, 1.22909998e-11,\n",
              "       1.14036254e-11, 1.24550387e-11, 9.99800146e-01, 1.10512346e-11,\n",
              "       1.20711930e-11, 1.19341091e-11, 1.25356652e-11, 1.17620930e-11,\n",
              "       1.21752469e-11, 1.18950214e-11], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdBzmsEaEKne"
      },
      "source": [
        "val_max = np.argmax(pred_results[0])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-hne48ZEKne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169e9d7e-2e5e-4902-a4b0-c806f977dcb8"
      },
      "source": [
        "for key,val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "print(k)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-PMCWWEKnf"
      },
      "source": [
        "#See probability:\n",
        "pred_results[0][val_max]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p85CmgdEKnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab60f9c-2213-4765-c965-1804e7f3dd4b"
      },
      "source": [
        "#Now, we can make our own questions using the vocabulary we have\n",
        "vocab"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_sKDuGwEKnf"
      },
      "source": [
        "my_story = 'Sandra picked up the milk . Mary travelled left . '"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGySN1PnEKnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571c8a3c-3e7d-4539-d5e4-d92160523115"
      },
      "source": [
        "my_story.split()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sandra',\n",
              " 'picked',\n",
              " 'up',\n",
              " 'the',\n",
              " 'milk',\n",
              " '.',\n",
              " 'Mary',\n",
              " 'travelled',\n",
              " 'left',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAZRk1VREKng"
      },
      "source": [
        "my_question = 'Sandra got the milk ?'"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXKuCcJNEKng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69be6556-250c-4e3c-bef2-08f64b67f147"
      },
      "source": [
        "my_question.split()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sandra', 'got', 'the', 'milk', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OuftUrFEKng"
      },
      "source": [
        "#Put the data in the same format as before\n",
        "my_data = [(my_story.split(), my_question.split(),'yes')]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqFbQE_cEKng"
      },
      "source": [
        "#Vectorize this data\n",
        "my_story, my_ques, my_ans = vectorize_stories(my_data)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziOkooT5EKng"
      },
      "source": [
        "#Make the prediction\n",
        "pred_results = model.predict(([my_story,my_ques]))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIvOHKA-EKnh"
      },
      "source": [
        "val_max = np.argmax(pred_results[0])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i6vCVFXEKnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd27a5a-8b72-4410-e44e-1c669cafb315"
      },
      "source": [
        "#Correct prediction!\n",
        "for key,val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "print(k)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYkZQHdFEKnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104d3145-106d-4b38-f6de-575998e94673"
      },
      "source": [
        "#Confidence\n",
        "pred_results[0][val_max]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7914729"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}